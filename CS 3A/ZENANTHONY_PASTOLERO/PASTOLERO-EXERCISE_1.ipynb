{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "954f69f5",
   "metadata": {},
   "source": [
    "1.\t(20 points) Determine whether the student passes (1) or fails (0) based on:\n",
    "a.\tHours studied\n",
    "b.\tHours of sleep\n",
    "c.\tHours of free time\n",
    "Given weights w1 = 0.6, w2, 0.4, bias = -3\n",
    "Step function with a threshold of 1 \n",
    "\n",
    "Predict the output of the following inputs:\n",
    "1.\t(x1, x2) = (8, 7)\n",
    "2.\t(x1, x2) = (3, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e2043b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (8, 7) => Weighted Sum: 4.60, Result: Pass\n",
      "Input (3, 4) => Weighted Sum: 0.40, Result: Fail\n"
     ]
    }
   ],
   "source": [
    "def step_function(value, threshold=1):\n",
    "    return 1 if value >= threshold else 0\n",
    "\n",
    "def perceptron_pass_fail(x1, x2, w1=0.6, w2=0.4, bias=-3):\n",
    "    weighted_sum = (x1 * w1) + (x2 * w2) + bias\n",
    "    output = step_function(weighted_sum, threshold=1)\n",
    "    result = \"Pass\" if output == 1 else \"Fail\"\n",
    "    return weighted_sum, result\n",
    "\n",
    "# Test cases\n",
    "inputs = [(8, 7), (3, 4)]\n",
    "for x1, x2 in inputs:\n",
    "    ws, res = perceptron_pass_fail(x1, x2)\n",
    "    print(f\"Input ({x1}, {x2}) => Weighted Sum: {ws:.2f}, Result: {res}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6610434",
   "metadata": {},
   "source": [
    "2.\t(20 points) Logic Gate Simulation. Given the following setup for a perceptron, compute its output and verify whether it acts as an AND gate.\n",
    "Given weights w1 = 1, w2 = 1, bias = -1.5\n",
    "Step function with a threshold of 0\n",
    "Inputs\t:\n",
    "\t(0,0) , (0,1), (1,0), (1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58096d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (0, 0) => Weighted Sum: -1.5, Output: 0\n",
      "Input (0, 1) => Weighted Sum: -0.5, Output: 0\n",
      "Input (1, 0) => Weighted Sum: -0.5, Output: 0\n",
      "Input (1, 1) => Weighted Sum: 0.5, Output: 1\n"
     ]
    }
   ],
   "source": [
    "def perceptron_and(x1, x2, w1=1, w2=1, bias=-1.5):\n",
    "    weighted_sum = (x1 * w1) + (x2 * w2) + bias\n",
    "    output = step_function(weighted_sum, threshold=0)\n",
    "    return weighted_sum, output\n",
    "\n",
    "inputs = [(0,0), (0,1), (1,0), (1,1)]\n",
    "for x1, x2 in inputs:\n",
    "    ws, out = perceptron_and(x1, x2)\n",
    "    print(f\"Input ({x1}, {x2}) => Weighted Sum: {ws}, Output: {out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeaf5fb",
   "metadata": {},
   "source": [
    "Truth Table Produced:\n",
    "\n",
    "(0,0) → 0\n",
    "\n",
    "(0,1) → 0\n",
    "\n",
    "(1,0) → 0\n",
    "\n",
    "(1,1) → 1\n",
    "\n",
    "The outputs exactly match the AND gate truth table. That means this perceptron successfully simulates the behavior of an AND gate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153e084f",
   "metadata": {},
   "source": [
    "3.\t(60 points) Perceptron comparison (One vs All). Given the 3 perceptron, using the same input, compute the output and decided on the predicted class is the WINNER. If a tie is present, compare and get the highest weighted sum. \n",
    "\n",
    "\n",
    "Inputs = [0.5, -1, 2, 1, 0]\n",
    "Perceptron A Configuration:\n",
    "•\tWeights: WA = [1.0, -0.5, 0.2, 0.1, 0.0]\n",
    "•\tBiasA: 0.2\n",
    "Perceptron B\n",
    "•\tWeights: WB = [0.2, 0.2, 0.5, -0.4, 0.3]\n",
    "•\tBiasB: 0.0\n",
    "Perceptron C\n",
    "•\tWeights: WC = [-0.3, -0.1, 0.4, 0.0, 0.2]\n",
    "•\tBiasC: -0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e67442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Weighted Sum = 1.7, Output = 1\n",
      "B: Weighted Sum = 0.5, Output = 1\n",
      "C: Weighted Sum = 0.15000000000000002, Output = 1\n",
      "Winner after tie-break: A\n"
     ]
    }
   ],
   "source": [
    "def perceptron_output(inputs, weights, bias):\n",
    "    weighted_sum = sum(x*w for x, w in zip(inputs, weights)) + bias\n",
    "    output = step_function(weighted_sum, threshold=0)\n",
    "    return weighted_sum, output\n",
    "\n",
    "inputs = [0.5, -1, 2, 1, 0]\n",
    "\n",
    "# Perceptron A\n",
    "WA = [1.0, -0.5, 0.2, 0.1, 0.0]\n",
    "wsA, outA = perceptron_output(inputs, WA, 0.2)\n",
    "\n",
    "# Perceptron B\n",
    "WB = [0.2, 0.2, 0.5, -0.4, 0.3]\n",
    "wsB, outB = perceptron_output(inputs, WB, 0.0)\n",
    "\n",
    "# Perceptron C\n",
    "WC = [-0.3, -0.1, 0.4, 0.0, 0.2]\n",
    "wsC, outC = perceptron_output(inputs, WC, -0.6)\n",
    "\n",
    "print(f\"A: Weighted Sum = {wsA}, Output = {outA}\")\n",
    "print(f\"B: Weighted Sum = {wsB}, Output = {outB}\")\n",
    "print(f\"C: Weighted Sum = {wsC}, Output = {outC}\")\n",
    "\n",
    "# Determine winner\n",
    "results = {\"A\": (wsA, outA), \"B\": (wsB, outB), \"C\": (wsC, outC)}\n",
    "active = {k: v for k, v in results.items() if v[1] == 1}\n",
    "\n",
    "if len(active) == 1:\n",
    "    print(\"Winner:\", list(active.keys())[0])\n",
    "elif len(active) > 1:\n",
    "    # tie: choose highest weighted sum\n",
    "    winner = max(active.items(), key=lambda x: x[1][0])[0]\n",
    "    print(\"Winner after tie-break:\", winner)\n",
    "else:\n",
    "    print(\"No perceptron fired (all outputs 0).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
