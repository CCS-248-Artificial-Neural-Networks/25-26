{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26dd4752",
   "metadata": {},
   "source": [
    "## VINCENT CORPES JR. | BSCS 3A   | CCS 246   |  EXERCISE FOR UNIT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083ca390",
   "metadata": {},
   "source": [
    "# 1. Choose either one of the following tasks (the output of this task will be used on the next number):\n",
    "a.\tDevelop a Class in Python called Dense_Layer (included in the submitted notebook).\n",
    "\n",
    "The chosen task should have the following functions:\n",
    "    a. (10 points) A function to setup/accept the inputs and weights\n",
    "    b. (10 points) A function to perform the weighted sum + bias\n",
    "    c. (15 points) A function to perform the selected activation function\n",
    "    d. (15 points) A function to calculate the loss (predicted output vs target output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "175a3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Dense_Layer:\n",
    "    def __init__(self, W=None, b=None, activation='LINEAR', name='D'):\n",
    "        self.W = None if W is None else np.array(W, dtype=float)\n",
    "        self.b = None if b is None else np.array(b, dtype=float)\n",
    "        self.activation_name = activation\n",
    "        self.name = name\n",
    "        self.X = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "\n",
    "    def set_params(self, W, b):\n",
    "        self.W = np.array(W, dtype=float)\n",
    "        self.b = np.array(b, dtype=float)\n",
    "\n",
    "    def set_input(self, X):\n",
    "        self.X = np.array(X, dtype=float)\n",
    "\n",
    "    def weighted_sum(self):\n",
    "        self.z = self.W.dot(self.X) + self.b\n",
    "        return self.z\n",
    "\n",
    "    def activate(self, z=None, func=None):\n",
    "        if z is None:\n",
    "            z = self.z\n",
    "        if func is None:\n",
    "            func = self.activation_name\n",
    "        if func.lower() == 'RELu':\n",
    "            self.a = np.maximum(0, z)\n",
    "        elif func.lower() == 'SIGMOID':\n",
    "            self.a = 1 / (1 + np.exp(-z))\n",
    "        elif func.lower() == 'LINEAAR':\n",
    "            self.a = z\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation\")\n",
    "        return self.a\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_loss(y_pred, y_true, loss='mse'):\n",
    "        y_pred = np.array(y_pred, dtype=float)\n",
    "        y_true = np.array(y_true, dtype=float)\n",
    "        if loss == 'mse':\n",
    "            return np.mean((y_pred - y_true)**2)\n",
    "        elif loss in ('bce', 'binary_crossentropy'):\n",
    "            eps = 1e-12\n",
    "            y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "            return -np.mean(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported loss type\")\n",
    "\n",
    "def detailed_dot_print(W_row, X, bias, neuron_idx=None):\n",
    "    terms = W_row * X\n",
    "    sum_terms = terms.sum()\n",
    "    z = sum_terms + bias\n",
    "    label = f\"Neuron {neuron_idx}: \" if neuron_idx else \"\"\n",
    "    print(f\"{label}{' + '.join([f'({w}*{x})' for w,x in zip(W_row, X)])} + ({bias}) = {z:.10f}\")\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab52fb",
   "metadata": {},
   "source": [
    "b. Given the following inputs from the Breast Cancer Dataset, using three features: Mean Radius, Mean Texture, and Mean Smoothness, determine whether the tumor is Benign (0) or Malignant (1) by calculating the network outputs step by step, given the following neural network configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6aa4cefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X: [14.1   20.3    0.095]\n",
      "\n",
      "-- Hidden Layer 1 --\n",
      "Neuron 1: (0.5*14.1) + (-0.3*20.3) + (0.8*0.095) + (0.3) = 1.3360000000\n",
      "Neuron 2: (0.2*14.1) + (0.4*20.3) + (-0.6*0.095) + (-0.5) = 10.3830000000\n",
      "Neuron 3: (-0.7*14.1) + (0.9*20.3) + (0.1*0.095) + (0.6) = 9.0095000000\n",
      "ReLU(z1) = [ 1.336  10.383   9.0095]\n",
      "\n",
      "-- Hidden Layer 2 --\n",
      "Neuron 1: (0.6*1.336) + (-0.2*10.383000000000001) + (0.4*9.0095) + (0.1) = 2.4288000000\n",
      "Neuron 2: (-0.3*1.336) + (0.5*10.383000000000001) + (0.7*9.0095) + (-0.8) = 10.2973500000\n",
      "Sigmoid(z2) = [0.91899725 0.99996628]\n",
      "\n",
      "-- Output Layer --\n",
      "Neuron 1: (0.7*0.9189972481200018) + (-0.5*0.9999662787960715) + (0.2) = 0.3433149343\n",
      "Sigmoid(z3) = 0.5849955347\n",
      "\n",
      "-- Losses --\n",
      "MSE Loss: 0.1722287062\n",
      "Binary Cross-Entropy Loss: 0.5361510648\n",
      "Predicted class (threshold 0.5): 1 (1=Malignant, 0=Benign)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corpe\\AppData\\Local\\Temp\\ipykernel_22336\\3278759382.py:50: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicted_class = int(a3 >= 0.5)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([14.1, 20.3, 0.095])\n",
    "target = np.array([1.0])\n",
    "\n",
    "W1 = np.array([[0.5, -0.3, 0.8],\n",
    "               [0.2,  0.4, -0.6],\n",
    "               [-0.7, 0.9, 0.1]])\n",
    "b1 = np.array([0.3, -0.5, 0.6])\n",
    "\n",
    "W2 = np.array([[0.6, -0.2, 0.4],\n",
    "               [-0.3, 0.5, 0.7]])\n",
    "b2 = np.array([0.1, -0.8])\n",
    "\n",
    "W3 = np.array([[0.7, -0.5]])\n",
    "b3 = np.array([0.2])\n",
    "\n",
    "print(\"Input X:\", X)\n",
    "\n",
    "# HIDDEN LAYER 1\n",
    "layer1 = Dense_Layer(W1, b1, activation='relu')\n",
    "layer1.set_input(X)\n",
    "z1 = layer1.weighted_sum()\n",
    "print(\"\\n-- Hidden Layer 1 --\")\n",
    "for i in range(W1.shape[0]):\n",
    "    detailed_dot_print(W1[i], X, b1[i], neuron_idx=i+1)\n",
    "a1 = np.maximum(0, z1)\n",
    "print(\"ReLU(z1) =\", np.round(a1, 10))\n",
    "\n",
    "# HIDDEN LAYER 2\n",
    "layer2 = Dense_Layer(W2, b2, activation='sigmoid')\n",
    "layer2.set_input(a1)\n",
    "z2 = layer2.weighted_sum()\n",
    "print(\"\\n-- Hidden Layer 2 --\")\n",
    "for i in range(W2.shape[0]):\n",
    "    detailed_dot_print(W2[i], a1, b2[i], neuron_idx=i+1)\n",
    "a2 = 1/(1+np.exp(-z2))\n",
    "print(\"Sigmoid(z2) =\", np.round(a2, 10))\n",
    "\n",
    "# OUTPUT LAYER\n",
    "layer3 = Dense_Layer(W3, b3, activation='sigmoid')\n",
    "layer3.set_input(a2)\n",
    "z3 = layer3.weighted_sum()\n",
    "print(\"\\n-- Output Layer --\")\n",
    "detailed_dot_print(W3[0], a2, b3[0], neuron_idx=1)\n",
    "a3 = 1/(1+np.exp(-z3))\n",
    "print(\"Sigmoid(z3) =\", round(a3[0], 10))\n",
    "\n",
    "# LOSS CALCULATION\n",
    "mse_loss = Dense_Layer.compute_loss(a3, target, loss='mse')\n",
    "bce_loss = Dense_Layer.compute_loss(a3, target, loss='bce')\n",
    "predicted_class = int(a3 >= 0.5)\n",
    "\n",
    "print(\"\\n-- Losses --\")\n",
    "print(f\"MSE Loss: {mse_loss:.10f}\")\n",
    "print(f\"Binary Cross-Entropy Loss: {bce_loss:.10f}\")\n",
    "print(f\"Predicted class (threshold 0.5): {predicted_class} (1=Malignant, 0=Benign)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
