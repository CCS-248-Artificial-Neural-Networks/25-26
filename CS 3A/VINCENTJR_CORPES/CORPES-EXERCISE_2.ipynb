{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26dd4752",
   "metadata": {},
   "source": [
    "## VINCENT CORPES JR. | BSCS 3A   | CCS 246   |  EXERCISE FOR UNIT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083ca390",
   "metadata": {},
   "source": [
    "# 1. Choose either one of the following tasks (the output of this task will be used on the next number):\n",
    "a.\tDevelop a Class in Python called Dense_Layer (included in the submitted notebook).\n",
    "\n",
    "The chosen task should have the following functions:\n",
    "    a. (10 points) A function to setup/accept the inputs and weights\n",
    "    b. (10 points) A function to perform the weighted sum + bias\n",
    "    c. (15 points) A function to perform the selected activation function\n",
    "    d. (15 points) A function to calculate the loss (predicted output vs target output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175a3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Dense_Layer:\n",
    "    def __init__(self, W=None, b=None, activation='linear', name='Dense'):\n",
    "        self.W = None if W is None else np.array(W, dtype=float)\n",
    "        self.b = None if b is None else np.array(b, dtype=float)\n",
    "        self.activation_name = activation\n",
    "        self.name = name\n",
    "        self.X = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "\n",
    "    def set_params(self, W, b):\n",
    "        self.W = np.array(W, dtype=float)\n",
    "        self.b = np.array(b, dtype=float)\n",
    "\n",
    "    def set_input(self, X):\n",
    "        self.X = np.array(X, dtype=float)\n",
    "\n",
    "    def weighted_sum(self):\n",
    "        self.z = self.W.dot(self.X) + self.b\n",
    "        return self.z\n",
    "\n",
    "    def activate(self, z=None, func=None):\n",
    "        if z is None:\n",
    "            z = self.z\n",
    "        if func is None:\n",
    "            func = self.activation_name\n",
    "        func = func.lower()\n",
    "\n",
    "        if func == 'relu':\n",
    "            self.a = np.maximum(0, z)\n",
    "        elif func == 'sigmoid':\n",
    "            self.a = 1 / (1 + np.exp(-z))\n",
    "        elif func == 'softmax':\n",
    "            exp_z = np.exp(z - np.max(z))  # for numerical stability\n",
    "            self.a = exp_z / np.sum(exp_z)\n",
    "        elif func == 'linear':\n",
    "            self.a = z\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation\")\n",
    "        return self.a\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_loss(y_pred, y_true, loss='mse'):\n",
    "        y_pred = np.array(y_pred, dtype=float)\n",
    "        y_true = np.array(y_true, dtype=float)\n",
    "        if loss == 'mse':\n",
    "            return np.mean((y_pred - y_true)**2)\n",
    "        elif loss in ('bce', 'binary_crossentropy'):\n",
    "            eps = 1e-12\n",
    "            y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "            return -np.mean(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n",
    "        elif loss in ('ce', 'categorical_crossentropy'):\n",
    "            eps = 1e-12\n",
    "            y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "            return -np.sum(y_true * np.log(y_pred))\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported loss type\")\n",
    "\n",
    "def detailed_dot_print(W_row, X, bias, neuron_idx=None):\n",
    "    terms = W_row * X\n",
    "    sum_terms = terms.sum()\n",
    "    z = sum_terms + bias\n",
    "    label = f\"Neuron {neuron_idx}: \" if neuron_idx else \"\"\n",
    "    print(f\"{label}{' + '.join([f'({w}*{x})' for w,x in zip(W_row, X)])} + ({bias}) = {z:.10f}\")\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64643f85",
   "metadata": {},
   "source": [
    "a. Given the following inputs from the Iris Dataset, using the sepal length, sepal width, petal length and petal width, determine what class (Iris-setosa, Iris-versicolor, and Iris-virginica) the following inputs are by calculating the output, given the neural network configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b7bbf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X: [5.1 3.5 1.4 0.2]\n",
      "\n",
      "-hIDDEN LAYER 1\n",
      "Neuron 1: (0.2*5.1) + (0.5*3.5) + (-0.3*1.4) + (0.1*0.2) + (3.0) = 5.3700000000\n",
      "Neuron 2: (-0.2*5.1) + (0.4*3.5) + (-0.4*1.4) + (0.3*0.2) + (-2.1) = -2.2200000000\n",
      "Neuron 3: (0.2*5.1) + (0.6*3.5) + (-0.1*1.4) + (0.5*0.2) + (0.6) = 3.6800000000\n",
      "ReLU(z1) = [5.37 0.   3.68]\n",
      "\n",
      "HIDDEN LAEER 2\n",
      "Neuron 1: (0.3*5.37) + (-0.5*0.0) + (0.7*3.68) + (4.3) = 8.4870000000\n",
      "Neuron 2: (0.2*5.37) + (-0.6*0.0) + (0.4*3.68) + (6.4) = 8.9460000000\n",
      "Sigmoid(z2) = [0.99979391 0.99986976]\n",
      "\n",
      "OUTPUT LAYER\n",
      "Neuron 1: (0.5*0.9997939117554883) + (-0.3*0.9998697598167464) + (-1.5) = -1.3000639721\n",
      "Neuron 2: (0.8*0.9997939117554883) + (-0.2*0.9998697598167464) + (2.1) = 2.6998611774\n",
      "Neuron 3: (0.6*0.9997939117554883) + (-0.4*0.9998697598167464) + (-3.3) = -3.1000715569\n",
      "Softmax(z3) = [0.01793421 0.97910131 0.00296448]\n",
      "\n",
      "LOSS\n",
      "Categorical Cross-Entropy Loss: 3.4010610373\n",
      "Predicted class index: 1 → Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "X = np.array([5.1, 3.5, 1.4, 0.2])\n",
    "target = np.array([0.7, 0.2, 0.1])  \n",
    "\n",
    "W1 = np.array([[0.2,  0.5, -0.3, 0.1],\n",
    "               [-0.2, 0.4, -0.4, 0.3],\n",
    "               [0.2,  0.6, -0.1, 0.5]])\n",
    "b1 = np.array([3.0, -2.1, 0.6])\n",
    "\n",
    "W2 = np.array([[0.3, -0.5, 0.7],\n",
    "               [0.2, -0.6, 0.4]])\n",
    "b2 = np.array([4.3, 6.4])\n",
    "\n",
    "W3 = np.array([[0.5, -0.3],\n",
    "               [0.8, -0.2],\n",
    "               [0.6, -0.4]])\n",
    "b3 = np.array([-1.5, 2.1, -3.3])\n",
    "\n",
    "print(\"Input X:\", X)\n",
    "\n",
    "# Hidden Layer 1\n",
    "layer1 = Dense_Layer(W1, b1, activation='relu')\n",
    "layer1.set_input(X)\n",
    "z1 = layer1.weighted_sum()\n",
    "print(\"\\n-hIDDEN LAYER 1\")\n",
    "for i in range(W1.shape[0]):\n",
    "    detailed_dot_print(W1[i], X, b1[i], neuron_idx=i+1)\n",
    "a1 = layer1.activate()\n",
    "print(\"ReLU(z1) =\", np.round(a1, 10))\n",
    "\n",
    "# Hidden Layer 2\n",
    "layer2 = Dense_Layer(W2, b2, activation='sigmoid')\n",
    "layer2.set_input(a1)\n",
    "z2 = layer2.weighted_sum()\n",
    "print(\"\\nHIDDEN LAEER 2\")\n",
    "for i in range(W2.shape[0]):\n",
    "    detailed_dot_print(W2[i], a1, b2[i], neuron_idx=i+1)\n",
    "a2 = layer2.activate()\n",
    "print(\"Sigmoid(z2) =\", np.round(a2, 10))\n",
    "\n",
    "# Output Layer (Softmax)\n",
    "layer3 = Dense_Layer(W3, b3, activation='softmax')\n",
    "layer3.set_input(a2)\n",
    "z3 = layer3.weighted_sum()\n",
    "print(\"\\nOUTPUT LAYER\")\n",
    "for i in range(W3.shape[0]):\n",
    "    detailed_dot_print(W3[i], a2, b3[i], neuron_idx=i+1)\n",
    "a3 = layer3.activate()\n",
    "print(\"Softmax(z3) =\", np.round(a3, 10))\n",
    "\n",
    "# Loss calculation\n",
    "ce_loss = Dense_Layer.compute_loss(a3, target, loss='ce')\n",
    "predicted_class = np.argmax(a3)\n",
    "\n",
    "print(\"\\nLOSS\")\n",
    "print(f\"Categorical Cross-Entropy Loss: {ce_loss:.10f}\")\n",
    "print(f\"Predicted class index: {predicted_class} → \"\n",
    "      f\"{['Iris-setosa','Iris-versicolor','Iris-virginica'][predicted_class]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab52fb",
   "metadata": {},
   "source": [
    "b. Given the following inputs from the Breast Cancer Dataset, using three features: Mean Radius, Mean Texture, and Mean Smoothness, determine whether the tumor is Benign (0) or Malignant (1) by calculating the network outputs step by step, given the following neural network configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa4cefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X: [14.1   20.3    0.095]\n",
      "\n",
      "HIDDEN LAYER 1\n",
      "Neuron 1: (0.5*14.1) + (-0.3*20.3) + (0.8*0.095) + (0.3) = 1.3360000000\n",
      "Neuron 2: (0.2*14.1) + (0.4*20.3) + (-0.6*0.095) + (-0.5) = 10.3830000000\n",
      "Neuron 3: (-0.7*14.1) + (0.9*20.3) + (0.1*0.095) + (0.6) = 9.0095000000\n",
      "ReLU(z1) = [ 1.336  10.383   9.0095]\n",
      "\n",
      "HIDDEN LAYER 2\n",
      "Neuron 1: (0.6*1.336) + (-0.2*10.383000000000001) + (0.4*9.0095) + (0.1) = 2.4288000000\n",
      "Neuron 2: (-0.3*1.336) + (0.5*10.383000000000001) + (0.7*9.0095) + (-0.8) = 10.2973500000\n",
      "Sigmoid(z2) = [0.91899725 0.99996628]\n",
      "\n",
      "OUTPUT LAYER\n",
      "Neuron 1: (0.7*0.9189972481200018) + (-0.5*0.9999662787960715) + (0.2) = 0.3433149343\n",
      "Sigmoid(z3) = 0.5849955347\n",
      "\n",
      "LOSS\n",
      "MSE Loss: 0.1722287062\n",
      "Binary Cross-Entropy Loss: 0.5361510648\n",
      "Predicted class: 1 (1 = Malignant, 0 = Benign)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corpe\\AppData\\Local\\Temp\\ipykernel_14840\\2738801299.py:53: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicted_class = int(a3 >= 0.5)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([14.1, 20.3, 0.095]) \n",
    "target = np.array([1.0])\n",
    "\n",
    "# First Hidden Layer\n",
    "W1 = np.array([[ 0.5, -0.3,  0.8],\n",
    "               [ 0.2,  0.4, -0.6],\n",
    "               [-0.7,  0.9,  0.1]])\n",
    "b1 = np.array([0.3, -0.5, 0.6])\n",
    "\n",
    "# Second Hidden Layer\n",
    "W2 = np.array([[ 0.6, -0.2,  0.4],\n",
    "               [-0.3,  0.5,  0.7]])\n",
    "b2 = np.array([0.1, -0.8])\n",
    "\n",
    "# Output Layer\n",
    "W3 = np.array([[0.7, -0.5]])\n",
    "b3 = np.array([0.2])\n",
    "\n",
    "print(\"Input X:\", X)\n",
    "\n",
    "# Hidden Layer 1\n",
    "layer1 = Dense_Layer(W1, b1, activation='relu')\n",
    "layer1.set_input(X)\n",
    "z1 = layer1.weighted_sum()\n",
    "print(\"\\nHIDDEN LAYER 1\")\n",
    "for i in range(W1.shape[0]):\n",
    "    detailed_dot_print(W1[i], X, b1[i], neuron_idx=i+1)\n",
    "a1 = layer1.activate()\n",
    "print(\"ReLU(z1) =\", np.round(a1, 10))\n",
    "\n",
    "# Hidden Layer 2\n",
    "layer2 = Dense_Layer(W2, b2, activation='sigmoid')\n",
    "layer2.set_input(a1)\n",
    "z2 = layer2.weighted_sum()\n",
    "print(\"\\nHIDDEN LAYER 2\")\n",
    "for i in range(W2.shape[0]):\n",
    "    detailed_dot_print(W2[i], a1, b2[i], neuron_idx=i+1)\n",
    "a2 = layer2.activate()\n",
    "print(\"Sigmoid(z2) =\", np.round(a2, 10))\n",
    "\n",
    "# Output Laye\n",
    "layer3 = Dense_Layer(W3, b3, activation='sigmoid')\n",
    "layer3.set_input(a2)\n",
    "z3 = layer3.weighted_sum()\n",
    "print(\"\\nOUTPUT LAYER\")\n",
    "detailed_dot_print(W3[0], a2, b3[0], neuron_idx=1)\n",
    "a3 = layer3.activate()\n",
    "print(\"Sigmoid(z3) =\", round(a3[0], 10))\n",
    "\n",
    "# Loss Clcculation\n",
    "mse_loss = Dense_Layer.compute_loss(a3, target, loss='mse')\n",
    "bce_loss = Dense_Layer.compute_loss(a3, target, loss='bce')\n",
    "predicted_class = int(a3 >= 0.5)\n",
    "\n",
    "print(\"\\nLOSS\")\n",
    "print(f\"MSE Loss: {mse_loss:.10f}\")\n",
    "print(f\"Binary Cross-Entropy Loss: {bce_loss:.10f}\")\n",
    "print(f\"Predicted class: {predicted_class} (1 = Malignant, 0 = Benign)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
