{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4b9c87",
   "metadata": {},
   "source": [
    "# 1. Neural Network Classification for Iris Dataset\n",
    "This notebook demonstrates a simple feedforward neural network using a custom `Dense_Layer` class to classify Iris species based on sepal and petal measurements.\n",
    "The network consists of three layers:\n",
    "- First Hidden Layer: Activation = ReLU\n",
    "- Second Hidden Layer: Activation = Sigmoid\n",
    "- Output Layer: Activation = Softmax\n",
    "You will see the step-by-step calculation for the following input:\n",
    "- Sepal length, sepal width, petal length, petal width "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c62c2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Dense_Layer:\n",
    "    def __init__(self, n_inputs, n_neurons, weights=None, biases=None):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_neurons = n_neurons\n",
    "        self.weights = weights if weights is not None else 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = biases if biases is not None else np.zeros((1, n_neurons))\n",
    "        self.inputs = None\n",
    "        self.output = None\n",
    "        self.activated_output = None\n",
    "    \n",
    "    def setup(self, inputs, weights=None, biases=None):\n",
    "        \"\"\"Accepts and sets the inputs, weights, and biases.\"\"\"\n",
    "        self.inputs = inputs\n",
    "        if weights is not None:\n",
    "            self.weights = weights\n",
    "        if biases is not None:\n",
    "            self.biases = biases\n",
    "    \n",
    "    def weighted_sum(self):\n",
    "        \"\"\"Performs weighted sum plus bias.\"\"\"\n",
    "        self.output = np.dot(self.inputs, self.weights) + self.biases\n",
    "        return self.output\n",
    "    \n",
    "    def activate(self, activation='relu'):\n",
    "        \"\"\"Applies the selected activation function.\"\"\"\n",
    "        if activation == 'relu':\n",
    "            self.activated_output = np.maximum(0, self.output)\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activated_output = 1 / (1 + np.exp(-self.output))\n",
    "        elif activation == 'tanh':\n",
    "            self.activated_output = np.tanh(self.output)\n",
    "        elif activation == 'softmax':\n",
    "            exp_values = np.exp(self.output - np.max(self.output, axis=1, keepdims=True))\n",
    "            self.activated_output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        else:\n",
    "            raise ValueError('Unsupported activation function')\n",
    "        return self.activated_output\n",
    "    \n",
    "    def calculate_loss(self, target_output, loss_type='mse'):\n",
    "        \"\"\"Calculates the loss between predicted and target output.\"\"\"\n",
    "        if loss_type == 'mse':\n",
    "            loss = np.mean((self.activated_output - target_output) ** 2)\n",
    "        elif loss_type == 'mae':\n",
    "            loss = np.mean(np.abs(self.activated_output - target_output))\n",
    "        else:\n",
    "            raise ValueError('Unsupported loss type')\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d40279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Hidden Layer Output (ReLU): [[3.93 0.15 0.85]]\n"
     ]
    }
   ],
   "source": [
    "# First Hidden Layer configuration and calculation\n",
    "X = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
    "target_output = np.array([[0.7, 0.2, 0.1]])\n",
    "W1 = np.array([[0.2, 0.5, -0.3], [0.1, -0.2, 0.4], [-0.4, 0.3, 0.2], [0.6, -0.1, 0.5]])\n",
    "B1 = np.array([[3.0, -2.1, 0.6]])\n",
    "layer1 = Dense_Layer(n_inputs=4, n_neurons=3)\n",
    "layer1.setup(inputs=X, weights=W1, biases=B1)\n",
    "layer1.weighted_sum()\n",
    "layer1.activate(activation='relu')\n",
    "print('First Hidden Layer Output (ReLU):', layer1.activated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f933b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Hidden Layer Output (Sigmoid): [[0.99378157 0.99187781]]\n"
     ]
    }
   ],
   "source": [
    "# Second Hidden Layer configuration and calculation\n",
    "W2 = np.array([[0.3, -0.5], [0.7, 0.2], [-0.6, 0.4]])\n",
    "B2 = np.array([[4.3, 6.4]])\n",
    "layer2_input = layer1.activated_output\n",
    "layer2 = Dense_Layer(n_inputs=3, n_neurons=2)\n",
    "layer2.setup(inputs=layer2_input, weights=W2, biases=B2)\n",
    "layer2.weighted_sum()\n",
    "layer2.activate(activation='sigmoid')\n",
    "print('Second Hidden Layer Output (Sigmoid):', layer2.activated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c973c827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Layer (Softmax): [[0.0265075  0.96865119 0.00484132]]\n",
      "Loss (MSE): 0.3511573252826841\n"
     ]
    }
   ],
   "source": [
    "# Output Layer configuration and calculation\n",
    "W3 = np.array([[0.5, -0.3, 0.8], [-0.2, 0.6, -0.4]])\n",
    "B3 = np.array([[-1.5, 2.1, -3.3]])\n",
    "layer3_input = layer2.activated_output\n",
    "layer3 = Dense_Layer(n_inputs=2, n_neurons=3)\n",
    "layer3.setup(inputs=layer3_input, weights=W3, biases=B3)\n",
    "layer3.weighted_sum()\n",
    "layer3.activate(activation='softmax')\n",
    "print('Output Layer (Softmax):', layer3.activated_output)\n",
    "loss = layer3.calculate_loss(target_output, loss_type='mse')\n",
    "print('Loss (MSE):', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e54997",
   "metadata": {},
   "source": [
    "# 2. Breast Cancer Dataset Classification\n",
    "This section demonstrates a neural network using the custom `Dense_Layer` class to classify tumors as Benign (0) or Malignant (1) based on three features: Mean Radius, Mean Texture, and Mean Smoothness.\n",
    "The network consists of three layers:\n",
    "- First Hidden Layer: Activation = ReLU\n",
    "- Second Hidden Layer: Activation = Sigmoid\n",
    "- Output Layer: Activation = Sigmoid\n",
    "You will see the step-by-step calculation for the given input and network configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4654e6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Hidden Layer Output (ReLU): [[11.3435  3.4755  0.    ]]\n",
      "Second Hidden Layer Output (Sigmoid): [[0.99975062 0.34618525]]\n",
      "Output Layer (Sigmoid): [[0.6740879]]\n",
      "Loss (MSE): 0.10621869619051845\n"
     ]
    }
   ],
   "source": [
    "# Breast Cancer Dataset - Step-by-step Neural Network Calculation\n",
    "# Inputs, weights, and biases from the image\n",
    "X = np.array([[14.1, 20.3, 0.095]])\n",
    "target_output = np.array([[1]])\n",
    "W1 = np.array([[0.5, -0.3, 0.8], [0.2, 0.4, -0.6], [-0.7, 0.9, 0.1]])\n",
    "B1 = np.array([[0.3, -0.5, 0.6]])\n",
    "layer1 = Dense_Layer(n_inputs=3, n_neurons=3)\n",
    "layer1.setup(inputs=X, weights=W1, biases=B1)\n",
    "layer1.weighted_sum()\n",
    "layer1.activate(activation='relu')\n",
    "print('First Hidden Layer Output (ReLU):', layer1.activated_output)\n",
    "\n",
    "# FIXED: W2 shape should be (3,2)\n",
    "W2 = np.array([[0.6, -0.2], [0.4, 0.7], [-0.3, 0.5]])\n",
    "B2 = np.array([[0.1, -0.8]])\n",
    "layer2_input = layer1.activated_output\n",
    "layer2 = Dense_Layer(n_inputs=3, n_neurons=2)\n",
    "layer2.setup(inputs=layer2_input, weights=W2, biases=B2)\n",
    "layer2.weighted_sum()\n",
    "layer2.activate(activation='sigmoid')\n",
    "print('Second Hidden Layer Output (Sigmoid):', layer2.activated_output)\n",
    "\n",
    "W3 = np.array([[0.7], [-0.5]])\n",
    "B3 = np.array([[0.2]])\n",
    "layer3_input = layer2.activated_output\n",
    "layer3 = Dense_Layer(n_inputs=2, n_neurons=1)\n",
    "layer3.setup(inputs=layer3_input, weights=W3, biases=B3)\n",
    "layer3.weighted_sum()\n",
    "layer3.activate(activation='sigmoid')\n",
    "print('Output Layer (Sigmoid):', layer3.activated_output)\n",
    "loss = layer3.calculate_loss(target_output, loss_type='mse')\n",
    "print('Loss (MSE):', loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
