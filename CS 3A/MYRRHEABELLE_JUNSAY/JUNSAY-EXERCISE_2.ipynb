{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27786922",
   "metadata": {},
   "source": [
    "# Exercise for Unit 2\n",
    "\n",
    "**Name:** MYRRHEA BELLE B. JUNSAY\n",
    "\n",
    "**Date:** SEPTEMBER 12, 2025\n",
    "\n",
    "**Year and Section:** BSCS 3A AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01e1df",
   "metadata": {},
   "source": [
    "## 1. Choose task\n",
    "\n",
    "**Chosen task:** \n",
    "\n",
    "a.\tDevelop a Class in Python called Dense_Layer (included in the submitted notebook). The chosen task should have the following functions:\n",
    "\n",
    "a) A function to setup/accept the inputs and weights\n",
    "\n",
    "b) A function to perform the weighted sum + bias\n",
    "\n",
    "c) A function to perform the selected activation function\n",
    "\n",
    "d) A function to calculate the loss (predicted output vs target output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7899d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# d. A function to setup/accept the inputs and weights\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# c. A function to calculate the loss\n",
    "def categorical_cross_entropy(y_pred, y_true):\n",
    "    y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    loss = -np.sum(y_true * np.log(y_pred_clipped))\n",
    "    return loss\n",
    "\n",
    "def binary_cross_entropy(y_pred, y_true):\n",
    "    y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    loss = -(y_true * np.log(y_pred_clipped) + (1 - y_true) * np.log(1 - y_pred_clipped))\n",
    "    return np.mean(loss)\n",
    "\n",
    "\n",
    "# Dense Layer Class\n",
    "class Dense_Layer:\n",
    "    \n",
    "    # a. A function to setup/accept the inputs and weights\n",
    "    def __init__(self, weights, biases):\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "        self.output = None\n",
    "\n",
    "    # b. A function to perform the weighted sum + bias\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a32489",
   "metadata": {},
   "source": [
    "## 2. Problem Set\n",
    "\n",
    "**Chosen problem set:** \n",
    "\n",
    "a) Given the inputs from the Iris Dataset, using the sepal length, sepal width, petal length and petal width, determine what class (Iris-setosa, Iris-versicolor, and Iris-virginica) the inputs are by calculating the output with the given the neural network configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "667c766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Dataset Calculation\n",
      "\n",
      "Hidden Layer 1 (Output): \n",
      "[[3.93 0.15 0.85]]\n",
      "\n",
      "Hidden Layer 2 (Output): \n",
      "[[0.99378157 0.99187781]]\n",
      "\n",
      "Final Predicted Output: \n",
      "[[0.0265075  0.96865119 0.00484132]]\n",
      "\n",
      "Loss: 3.0807\n",
      "\n",
      "Predicted Class: Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "print(\"Iris Dataset Calculation\\n\")\n",
    "\n",
    "# Input features\n",
    "X_iris = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
    "# Target output \n",
    "target_iris = np.array([[0.7, 0.2, 0.1]])\n",
    "\n",
    "# Layer 1\n",
    "W1_iris = np.array([[0.2, 0.5, -0.3], [0.1, -0.2, 0.4], [-0.4, 0.3, 0.2], [0.6, -0.1, 0.5]])\n",
    "B1_iris = np.array([[3.0, -2.1, 0.6]])\n",
    "activation1_iris = relu\n",
    "\n",
    "# Layer 2\n",
    "W2_iris = np.array([[0.3, -0.5], [0.7, 0.2], [-0.6, 0.4]])\n",
    "B2_iris = np.array([[4.3, 6.4]])\n",
    "activation2_iris = sigmoid\n",
    "\n",
    "# Layer 3 (Output) \n",
    "W3_iris = np.array([[0.5, -0.3, 0.8], [-0.2, 0.6, -0.4]])\n",
    "B3_iris = np.array([[-1.5, 2.1, -3.3]])\n",
    "activation3_iris = softmax\n",
    "\n",
    "# First Hidden Layer\n",
    "layer1 = Dense_Layer(W1_iris, B1_iris)\n",
    "output1_raw = layer1.forward(X_iris)\n",
    "output1_activated = activation1_iris(output1_raw)\n",
    "print(f\"Hidden Layer 1 (Output): \\n{output1_activated}\\n\")\n",
    "\n",
    "# Second Hidden Layer\n",
    "layer2 = Dense_Layer(W2_iris, B2_iris)\n",
    "output2_raw = layer2.forward(output1_activated)\n",
    "output2_activated = activation2_iris(output2_raw)\n",
    "\n",
    "print(f\"Hidden Layer 2 (Output): \\n{output2_activated}\\n\")\n",
    "\n",
    "# Output Layer\n",
    "layer3 = Dense_Layer(W3_iris, B3_iris)\n",
    "output3_raw = layer3.forward(output2_activated)\n",
    "final_output_iris = activation3_iris(output3_raw)\n",
    "\n",
    "print(f\"Final Predicted Output: \\n{final_output_iris}\\n\")\n",
    "\n",
    "# Loss Calculation\n",
    "loss_iris = categorical_cross_entropy(final_output_iris, target_iris)\n",
    "print(f\"Loss: {loss_iris:.4f}\")\n",
    "\n",
    "predicted_class_index = np.argmax(final_output_iris)\n",
    "classes = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
    "print(f\"\\nPredicted Class: {classes[predicted_class_index]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
