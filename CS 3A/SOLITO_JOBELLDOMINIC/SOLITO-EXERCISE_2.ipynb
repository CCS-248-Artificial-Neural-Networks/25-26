{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd0a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - Amparo\n",
    "import numpy as np \n",
    "\n",
    "class Dense_Layer:\n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.output = None\n",
    "\n",
    "    def set(self, inputs, weights, bias):\n",
    "        self.inputs = np.array(inputs)\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "        self.output = None\n",
    "\n",
    "    def weighted_sum(self):\n",
    "        return np.dot(self.inputs, self.weights) + self.bias\n",
    "\n",
    "    def activation(self, z, function=\"relu\"):\n",
    "        function = function.lower()   # always lowercase for consistency\n",
    "        if function == \"relu\":\n",
    "            return np.maximum(0, z)\n",
    "        elif function == \"sigmoid\":\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "        elif function == \"tanh\":\n",
    "            return np.tanh(z)\n",
    "        elif function == \"softmax\":\n",
    "            exp_vals = np.exp(z - np.max(z))  \n",
    "            return exp_vals / np.sum(exp_vals)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "    def loss(self, predicted, target):\n",
    "\n",
    "        predicted = np.array(predicted)\n",
    "        target = np.array(target)\n",
    "\n",
    "        predicted = np.clip(predicted, 1e-15, 1 - 1e-15)\n",
    "        return -np.sum(target * np.log(predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "285131f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 Output: [3.93 0.15 0.85]\n",
      "Layer 2 Output: [0.99378157 0.99187781]\n",
      "Final Output (probabilities): [0.0265075  0.96865119 0.00484132]\n",
      "Loss: 3.077471334911406\n",
      "Predicted Class: Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "#2A - Amparo\n",
    "classes = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"] # 2A- Amparo\n",
    "\n",
    "X = [5.1, 3.5, 1.4, 0.2]      \n",
    "W1 = [[0.2, 0.5, -0.3], [0.1, -0.2, 0.4], [-0.4, 0.3, 0.2], [0.6, -0.1, 0.5]]       \n",
    "B1 = [3.0, -2.1, 0.6]            \n",
    "target_output = [0.7, 0.1, 0.1]\n",
    "\n",
    "W2 = [[0.3, -0.5], [0.7, 0.2], [-0.6, 0.4]]  \n",
    "B2 = [4.3, 6.4]\n",
    "\n",
    "W3 = [[0.5, -0.3, 0.8], [-0.2, 0.6, -0.4]]\n",
    "B3 = [-1.5, 2.1, -3.3]\n",
    "\n",
    "layer1 = Dense_Layer()\n",
    "layer1.set(X, W1, B1)\n",
    "a1 = layer1.activation(layer1.weighted_sum(), \"relu\")\n",
    "print(\"Layer 1 Output:\", a1)\n",
    "\n",
    "layer2 = Dense_Layer()\n",
    "layer2.set(a1, W2, B2)\n",
    "a2 = layer2.activation(layer2.weighted_sum(), \"sigmoid\")\n",
    "print(\"Layer 2 Output:\", a2)\n",
    "\n",
    "layer3 = Dense_Layer()\n",
    "layer3.set(a2, W3, B3)\n",
    "a3 = layer3.activation(layer3.weighted_sum(), \"softmax\")\n",
    "print(\"Final Output (probabilities):\", a3)\n",
    "\n",
    "pred_class = classes[np.argmax(a3)]\n",
    "loss = layer3.loss(a3, target_output)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Predicted Class:\", pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b96c214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - Solito\n",
    "import numpy as np \n",
    "\n",
    "class Dense_Layer:\n",
    "    def __init__(self, function=\"relu\"):\n",
    "        self.function = function\n",
    "    \n",
    "    def set_inputs_weights(self, inputs, weights, bias):\n",
    "        self.inputs = np.array(inputs)\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "\n",
    "    def weighted_sum(self):\n",
    "        self.z = np.dot(self.weights, self.inputs) + self.bias\n",
    "        return self.z\n",
    "\n",
    "    def activate(self):\n",
    "        if self.function == \"relu\":\n",
    "            self.a = np.maximum(0, self.z)\n",
    "        elif self.function == \"sigmoid\":\n",
    "            self.a = 1 / (1 + np.exp(-self.z))\n",
    "        return self.a\n",
    "\n",
    "    def calculate_loss(self, target):\n",
    "        target = np.array(target)\n",
    "        return np.mean((self.a - target) ** 2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a000cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2 = [0.91899725 0.99996628]\n",
      "Loss = 0.17222870621762063\n",
      "Prediction:  1\n"
     ]
    }
   ],
   "source": [
    "#2B - Solito\n",
    "X = [14.1, 20.3, 0.095]\n",
    "Target_output = [1]\n",
    "threshold = 0.5\n",
    "\n",
    "W1 = [[0.5, -0.3, 0.8], [0.2,  0.4, -0.6], [-0.7, 0.9, 0.1]]\n",
    "B1 = [0.3, -0.5, 0.6]\n",
    "\n",
    "firstlayer = Dense_Layer(function=\"relu\")\n",
    "firstlayer.set_inputs_weights(X, W1, B1)\n",
    "\n",
    "S1 = firstlayer.weighted_sum()\n",
    "H1 = firstlayer.activate()\n",
    "\n",
    "W2 = [[0.6, -0.2, 0.4], [-0.3, 0.5, 0.7]]\n",
    "B2 = [0.1, -0.8]\n",
    "\n",
    "secondlayer = Dense_Layer(function=\"sigmoid\")\n",
    "secondlayer.set_inputs_weights(H1, W2, B2)\n",
    "\n",
    "S2 = secondlayer.weighted_sum()\n",
    "H2 = secondlayer.activate()\n",
    "\n",
    "print(\"H2 =\", H2)\n",
    "\n",
    "W3 = [[0.7, -0.5]]\n",
    "B3 = [0.2]\n",
    "\n",
    "thirdlayer = Dense_Layer(function=\"sigmoid\")\n",
    "thirdlayer.set_inputs_weights(H2, W3, B3)\n",
    "\n",
    "S3 = thirdlayer.weighted_sum()\n",
    "H3 = thirdlayer.activate()\n",
    "\n",
    "threshold = 0.5\n",
    "prediction = 1 if H3 >= threshold else 0\n",
    "\n",
    "loss = thirdlayer.calculate_loss(Target_output)\n",
    "print(\"Loss =\", loss)\n",
    "print(\"Prediction: \", prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
