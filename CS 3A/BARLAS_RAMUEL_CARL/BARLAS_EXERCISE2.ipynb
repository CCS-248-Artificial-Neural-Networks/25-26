{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fab792a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e91acdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Activation Function\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x))\n",
    "    return exps / np.sum(exps)\n",
    "\n",
    "# Define Loss\n",
    "\n",
    "def mse(y_pred, y_true):\n",
    "    return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a4624a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense_Layer\n",
    "\n",
    "class Dense_Layer:\n",
    "    def __init__(self, weights, bias, activation):\n",
    "        self.weights = np.array(weights, dtype=float)\n",
    "        self.bias = np.array(bias, dtype=float)\n",
    "        self.activation = activation\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Isolate Array into Float\n",
    "        self.n_input = np.array(inputs, dtype=float)\n",
    "\n",
    "        # Calculate Weighted Sum = (inputs * weights) + bias\n",
    "        z = np.dot(self.weights, self.n_input) + self.bias\n",
    "\n",
    "        # Activate Func\n",
    "        self.output = self.activation_function(z)\n",
    "        return self.output\n",
    "\n",
    "\n",
    "    def activation_function(self, z):\n",
    "\n",
    "        # Performs Selected Activation Function\n",
    "\n",
    "        if self.activation == 'relu':\n",
    "            return relu(z)\n",
    "        \n",
    "        elif self.activation == 'sigmoid':\n",
    "            return sigmoid(z)\n",
    "        \n",
    "        elif self.activation == 'softmax':\n",
    "            return softmax(z)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function {self.activation} not supported.\")\n",
    "\n",
    "\n",
    "    def compute_loss(self, target, loss_type='mse'):\n",
    "        y_true = np.array(target, dtype=float)\n",
    "        y_pred = self.output\n",
    "\n",
    "        if loss_type == 'mse':\n",
    "            return mse(y_pred, y_true)\n",
    "        \n",
    "        elif loss_type == 'crossentropy':\n",
    "            return cross_entropy(y_pred, y_true)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported loss {loss_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c386e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iris Dataset\n",
    "\n",
    "X = [5.1, 3.5, 1.4, 0.2]\n",
    "target_output = [0.7, 0.2, 0.1]\n",
    "\n",
    "W1 = [\n",
    "    [0.2, 0.1, -0.4, 0.6],\n",
    "    [0.5, -0.2, 0.3, -0.1],\n",
    "    [-0.3, 0.4, 0.2, 0.5]\n",
    "]\n",
    "B1 = [3.0, -2.1, 0.6]    \n",
    "\n",
    "W2 = [\n",
    "    [0.3, 0.7, -0.6],\n",
    "    [-0.5, 0.2, 0.4]\n",
    "]\n",
    "B2 = [4.3, 6.4]    \n",
    "      \n",
    "W3 = [\n",
    "    [0.5, 0.2],\n",
    "    [-0.3, 0.6],\n",
    "    [0.8, -0.4]\n",
    "]\n",
    "B3 = [-1.5, 2.1, -3.3]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "80ac76d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output:\n",
      "  Iris-setosa: 0.038914\n",
      "  Iris-versicolor: 0.956306\n",
      "  Iris-virginica: 0.004780\n",
      "\n",
      "Predicted Class: Iris-versicolor\n",
      "Calculated Loss (Cross Entrophy): 2.8157567461372666\n"
     ]
    }
   ],
   "source": [
    "#Layers\n",
    "\n",
    "layer1 = Dense_Layer(W1, B1, activation='relu')\n",
    "out1 = layer1.forward(X)\n",
    "\n",
    "layer2 = Dense_Layer(W2, B2, activation='sigmoid')\n",
    "out2 = layer2.forward(out1)\n",
    "\n",
    "layer3 = Dense_Layer(W3, B3, activation='softmax')\n",
    "out3 = layer3.forward(out2)\n",
    "\n",
    "classes = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
    "pred_idx = np.argmax(out3)\n",
    "predicted_class = classes[pred_idx]\n",
    "\n",
    "print(\"Final Output:\")\n",
    "for cls, prob in zip(classes, out3):\n",
    "    print(f\"  {cls}: {prob:.6f}\")\n",
    "\n",
    "print(f\"\\nPredicted Class: {predicted_class}\")\n",
    "\n",
    "loss = layer3.compute_loss(target_output, loss_type='crossentropy')\n",
    "print(\"Calculated Loss (Cross Entrophy):\", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
