{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cda560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5fae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------\n",
    "# Functions\n",
    "# --------------------------\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x))\n",
    "    return exps / np.sum(exps)\n",
    "\n",
    "def mse_loss(y_pred, y_true):\n",
    "    return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    # y_true is one-hot encoded\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d4e4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------\n",
    "# Dense Layer \n",
    "# --------------------------\n",
    "class Dense_Layer:\n",
    "    def __init__(self, weights, bias, activation):\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "        self.activation = activation\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = np.array(inputs)\n",
    "        self.z = np.dot(self.inputs, self.weights) + self.bias\n",
    "        # Apply chosen activation\n",
    "        if self.activation == \"relu\":\n",
    "            self.output = relu(self.z)\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            self.output = sigmoid(self.z)\n",
    "        elif self.activation == \"softmax\":\n",
    "            self.output = softmax(self.z)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown activation function\")\n",
    "        return self.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4649816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Iris Dataset Example ===\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------\n",
    "# Iris Dataset\n",
    "# --------------------------\n",
    "print(\"=== Iris Dataset Example ===\")\n",
    "\n",
    "# sepal length, sepal width, petal length, petal width\n",
    "X = np.array([5.1, 3.5, 1.4, 0.2])\n",
    "target_output = np.array([1, 0, 0])  # Iris-setosa (one-hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a17aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First hidden layer\n",
    "W1 = np.random.randn(4, 5)  # 4 inputs → 5 hidden neurons\n",
    "B1 = np.random.randn(5)\n",
    "layer1 = Dense_Layer(W1, B1, \"relu\")\n",
    "out1 = layer1.forward(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00399b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Second hidden layer\n",
    "W2 = np.random.randn(5, 3)  # 5 hidden → 3 hidden\n",
    "B2 = np.random.randn(3)\n",
    "layer2 = Dense_Layer(W2, B2, \"sigmoid\")\n",
    "out2 = layer2.forward(out1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a307233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Output layer\n",
    "W3 = np.random.randn(3, 3)  # 3 hidden → 3 outputs (species)\n",
    "B3 = np.random.randn(3)\n",
    "layer3 = Dense_Layer(W3, B3, \"softmax\")\n",
    "out3 = layer3.forward(out2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "272a14ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prediction (Softmax probs): [0.68385641 0.26994128 0.04620231]\n",
      "Loss (Cross-Entropy): 0.3800073084069838\n",
      "Predicted Class: Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# Print final prediction and determine class\n",
    "print(\"Final Prediction (Softmax probs):\", out3)\n",
    "print(\"Loss (Cross-Entropy):\", cross_entropy_loss(out3, target_output))\n",
    "\n",
    "# Determine the class based on the highest probability\n",
    "classes = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
    "predicted_class = classes[np.argmax(out3)]\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b4024cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Breast Cancer Dataset Example ===\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------\n",
    "# Breast Cancer Dataset\n",
    "# --------------------------\n",
    "print(\"\\n=== Breast Cancer Dataset Example ===\")\n",
    "\n",
    "# mean radius, mean texture, mean smoothness\n",
    "X_bc = np.array([14.5, 20.1, 0.1])\n",
    "target_output_bc = np.array([1])  # Malignant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9a62875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First hidden layer\n",
    "W1_bc = np.random.randn(3, 4)  # 3 inputs → 4 hidden neurons\n",
    "B1_bc = np.random.randn(4)\n",
    "layer1_bc = Dense_Layer(W1_bc, B1_bc, \"relu\")\n",
    "out1_bc = layer1_bc.forward(X_bc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a70990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Second hidden layer\n",
    "W2_bc = np.random.randn(4, 2)  # 4 hidden → 2 hidden\n",
    "B2_bc = np.random.randn(2)\n",
    "layer2_bc = Dense_Layer(W2_bc, B2_bc, \"sigmoid\")\n",
    "out2_bc = layer2_bc.forward(out1_bc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65d93b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Output layer\n",
    "W3_bc = np.random.randn(2, 1)  # 2 hidden → 1 output\n",
    "B3_bc = np.random.randn(1)\n",
    "layer3_bc = Dense_Layer(W3_bc, B3_bc, \"sigmoid\")\n",
    "out3_bc = layer3_bc.forward(out2_bc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00e5e2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prediction (Sigmoid): [0.73853547]\n",
      "Loss (MSE): 0.0683636984262476\n",
      "Tumor Classification: Malignant (1)\n"
     ]
    }
   ],
   "source": [
    "# Print final prediction and tumor classification\n",
    "print(\"Final Prediction (Sigmoid):\", out3_bc)\n",
    "print(\"Loss (MSE):\", mse_loss(out3_bc, target_output_bc))\n",
    "\n",
    "# Classify tumor based on sigmoid output\n",
    "if out3_bc >= 0.5:\n",
    "    print(\"Tumor Classification: Malignant (1)\")\n",
    "else:\n",
    "    print(\"Tumor Classification: Benign (0)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
