{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4425596,"sourceType":"datasetVersion","datasetId":2585786},{"sourceId":4749004,"sourceType":"datasetVersion","datasetId":2733586},{"sourceId":14425010,"sourceType":"datasetVersion","datasetId":9213610}],"dockerImageVersionId":31234,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"35c8ad95","cell_type":"code","source":"# Lib imports\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import ResNet50\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:30:48.890697Z","iopub.execute_input":"2026-01-07T15:30:48.891617Z","iopub.status.idle":"2026-01-07T15:30:48.896514Z","shell.execute_reply.started":"2026-01-07T15:30:48.891583Z","shell.execute_reply":"2026-01-07T15:30:48.895399Z"},"_kg_hide-output":false},"outputs":[],"execution_count":128},{"id":"6cf51c0b","cell_type":"code","source":"# DATASET DIRECTORY CONFIGURATION\n# Download and unzip the dataset from Kaggle, set the directory paths accordingly.\ntrain_dir = \"/kaggle/input/pizza-classification-data/train\"  # e.g. './muffin-vs-chihuahua/train'\ntest_dir = \"/kaggle/input/pizza-classification-data/test\"    # e.g. './muffin-vs-chihuahua/test'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:30:48.898328Z","iopub.execute_input":"2026-01-07T15:30:48.898693Z","iopub.status.idle":"2026-01-07T15:30:48.903218Z","shell.execute_reply.started":"2026-01-07T15:30:48.898665Z","shell.execute_reply":"2026-01-07T15:30:48.902221Z"}},"outputs":[],"execution_count":129},{"id":"ef4f9d80","cell_type":"code","source":"# IMAGE PARAMETERS\n# Used to resize the input images, also will determine the input size of your input layer.\nIMG_SIZE = (128, 128)\nBATCH_SIZE = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:30:48.904374Z","iopub.execute_input":"2026-01-07T15:30:48.904694Z","iopub.status.idle":"2026-01-07T15:30:48.908559Z","shell.execute_reply.started":"2026-01-07T15:30:48.904670Z","shell.execute_reply":"2026-01-07T15:30:48.907863Z"}},"outputs":[],"execution_count":130},{"id":"d350739e","cell_type":"code","source":"# DATA PREPROCESSING & AUGMENTATION\n# Optional but recommended for image processing tasks, especially with limited data.\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    validation_split=0.2\n)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='training'\n)\nval_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='validation'\n)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle=False\n)\n\n# Load ResNet50 with pretrained ImageNet weights\nbase_model = ResNet50(\n    weights='/kaggle/input/resnet50-weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n    include_top=False,  # Exclude final classification layers\n    input_shape=(128, 128, 3)\n)\n\n# Freeze the base model\nbase_model.trainable = False\n\n# Build custom classification head\nmodel_resnet = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1, activation='sigmoid')  # Binary classification\n])\n\n# Compile with lower learning rate for transfer learning\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:30:48.911064Z","iopub.execute_input":"2026-01-07T15:30:48.911366Z","iopub.status.idle":"2026-01-07T15:30:52.868542Z","shell.execute_reply.started":"2026-01-07T15:30:48.911341Z","shell.execute_reply":"2026-01-07T15:30:52.867565Z"}},"outputs":[{"name":"stdout","text":"Found 1280 images belonging to 2 classes.\nFound 320 images belonging to 2 classes.\nFound 366 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":131},{"id":"71dcbcb7","cell_type":"code","source":"# Configure the model optimizers, loss function, and metrics\nmodel_resnet.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel_resnet.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:30:52.869691Z","iopub.execute_input":"2026-01-07T15:30:52.869972Z","iopub.status.idle":"2026-01-07T15:30:52.901259Z","shell.execute_reply.started":"2026-01-07T15:30:52.869948Z","shell.execute_reply":"2026-01-07T15:30:52.900194Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_8\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,112,513\u001b[0m (91.98 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,112,513</span> (91.98 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m524,801\u001b[0m (2.00 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">524,801</span> (2.00 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n</pre>\n"},"metadata":{}}],"execution_count":132},{"id":"750c313f","cell_type":"code","source":"# TRAINING THE CNN\nhistory = model.fit(\n    train_generator,\n    epochs=10,\n    validation_data=val_generator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:30:52.902707Z","iopub.execute_input":"2026-01-07T15:30:52.903150Z","iopub.status.idle":"2026-01-07T15:35:58.904740Z","shell.execute_reply.started":"2026-01-07T15:30:52.903077Z","shell.execute_reply":"2026-01-07T15:35:58.903664Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 703ms/step - accuracy: 0.7290 - loss: 0.5402 - val_accuracy: 0.7094 - val_loss: 0.5887\nEpoch 2/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 685ms/step - accuracy: 0.7309 - loss: 0.5325 - val_accuracy: 0.6031 - val_loss: 0.7347\nEpoch 3/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 702ms/step - accuracy: 0.7604 - loss: 0.5070 - val_accuracy: 0.8031 - val_loss: 0.5024\nEpoch 4/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 687ms/step - accuracy: 0.7440 - loss: 0.5284 - val_accuracy: 0.6187 - val_loss: 0.6320\nEpoch 5/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 695ms/step - accuracy: 0.7750 - loss: 0.4834 - val_accuracy: 0.6719 - val_loss: 0.5990\nEpoch 6/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 681ms/step - accuracy: 0.7707 - loss: 0.5088 - val_accuracy: 0.7844 - val_loss: 0.4816\nEpoch 7/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 711ms/step - accuracy: 0.7732 - loss: 0.4655 - val_accuracy: 0.7812 - val_loss: 0.4716\nEpoch 8/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 687ms/step - accuracy: 0.7818 - loss: 0.4489 - val_accuracy: 0.8000 - val_loss: 0.4732\nEpoch 9/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 688ms/step - accuracy: 0.7911 - loss: 0.4602 - val_accuracy: 0.8094 - val_loss: 0.4330\nEpoch 10/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 682ms/step - accuracy: 0.7457 - loss: 0.5195 - val_accuracy: 0.7594 - val_loss: 0.5101\n","output_type":"stream"}],"execution_count":133},{"id":"7541833a","cell_type":"code","source":"# EVALUATE THE MODEL\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(f\"Test Accuracy: {test_acc}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:35:58.906037Z","iopub.execute_input":"2026-01-07T15:35:58.906480Z","iopub.status.idle":"2026-01-07T15:36:01.708367Z","shell.execute_reply.started":"2026-01-07T15:35:58.906430Z","shell.execute_reply":"2026-01-07T15:36:01.707220Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - accuracy: 0.6422 - loss: 0.7034\nTest Accuracy: 0.7404371500015259\n","output_type":"stream"}],"execution_count":134},{"id":"2ad7d399","cell_type":"code","source":"# SAVE THE MODEL\nmodel.save('/kaggle/working/models/exercise_6_custom_tambalo.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:36:01.709802Z","iopub.execute_input":"2026-01-07T15:36:01.710201Z","iopub.status.idle":"2026-01-07T15:36:01.831166Z","shell.execute_reply.started":"2026-01-07T15:36:01.710163Z","shell.execute_reply":"2026-01-07T15:36:01.829829Z"}},"outputs":[{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"}],"execution_count":135},{"id":"45472d3e","cell_type":"code","source":"# SIMPLE INFERENCE SCRIPT\nfrom tensorflow.keras.preprocessing import image\n\ndef predict_image(img_path, model_path='/kaggle/working/models/exercise_6_custom_tambalo.h5'):\n    model = tf.keras.models.load_model(model_path)\n    img = image.load_img(img_path, target_size=IMG_SIZE)\n    img_array = image.img_to_array(img) / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n    pred = model.predict(img_array)[0,0]\n    label = \"Pizza\" if pred >= 0.5 else \"Not Pizza\"\n    print(f\"Prediction: {label} (confidence: {pred:.2f})\")\n    return pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:36:01.832500Z","iopub.execute_input":"2026-01-07T15:36:01.832857Z","iopub.status.idle":"2026-01-07T15:36:01.839568Z","shell.execute_reply.started":"2026-01-07T15:36:01.832822Z","shell.execute_reply":"2026-01-07T15:36:01.838558Z"}},"outputs":[],"execution_count":136},{"id":"b340f1d2","cell_type":"code","source":"# Example usage:\npred1 = predict_image(\"/kaggle/input/pizza-classification-data/test/not_pizza/3140015.jpg\")\npred2 = predict_image(\"/kaggle/input/pizza-classification-data/test/not_pizza/3194027.jpg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:36:01.842199Z","iopub.execute_input":"2026-01-07T15:36:01.842619Z","iopub.status.idle":"2026-01-07T15:36:02.532049Z","shell.execute_reply.started":"2026-01-07T15:36:01.842590Z","shell.execute_reply":"2026-01-07T15:36:02.531207Z"}},"outputs":[{"name":"stderr","text":"WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","output_type":"stream"},{"name":"stdout","text":"Prediction: Not Pizza (confidence: 0.49)\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\nPrediction: Not Pizza (confidence: 0.41)\n","output_type":"stream"}],"execution_count":137}]}