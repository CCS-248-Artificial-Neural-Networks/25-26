{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4749004,"sourceType":"datasetVersion","datasetId":2733586},{"sourceId":117206760,"sourceType":"kernelVersion"}],"dockerImageVersionId":31234,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"6904d94a","cell_type":"markdown","source":"This is an example of a simple CNN developed, trained and utilized\n\nAI was used to help generate the codebase\n\nNote: Make sure that the tensorflow package is installed in your device.","metadata":{}},{"id":"35c8ad95","cell_type":"code","source":"# Lib imports\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models, regularizers\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T13:57:11.895827Z","iopub.execute_input":"2026-01-07T13:57:11.896991Z","iopub.status.idle":"2026-01-07T13:57:11.902181Z","shell.execute_reply.started":"2026-01-07T13:57:11.896925Z","shell.execute_reply":"2026-01-07T13:57:11.901244Z"},"_kg_hide-output":false},"outputs":[],"execution_count":77},{"id":"6cf51c0b","cell_type":"code","source":"# DATASET DIRECTORY CONFIGURATION\n# Download and unzip the dataset from Kaggle, set the directory paths accordingly.\ntrain_dir = \"/kaggle/input/muffin-vs-chihuahua-image-classification/train\"  # e.g. './muffin-vs-chihuahua/train'\ntest_dir = \"/kaggle/input/muffin-vs-chihuahua-image-classification/test\"    # e.g. './muffin-vs-chihuahua/test'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T13:57:11.914086Z","iopub.execute_input":"2026-01-07T13:57:11.914541Z","iopub.status.idle":"2026-01-07T13:57:11.922385Z","shell.execute_reply.started":"2026-01-07T13:57:11.914512Z","shell.execute_reply":"2026-01-07T13:57:11.921339Z"}},"outputs":[],"execution_count":78},{"id":"ef4f9d80","cell_type":"code","source":"# IMAGE PARAMETERS\n# Used to resize the input images, also will determine the input size of your input layer.\nIMG_SIZE = (128, 128)\nBATCH_SIZE = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T13:57:11.924120Z","iopub.execute_input":"2026-01-07T13:57:11.924575Z","iopub.status.idle":"2026-01-07T13:57:11.949944Z","shell.execute_reply.started":"2026-01-07T13:57:11.924546Z","shell.execute_reply":"2026-01-07T13:57:11.948409Z"}},"outputs":[],"execution_count":79},{"id":"d350739e","cell_type":"code","source":"# DATA PREPROCESSING & AUGMENTATION\n# Optional but recommended for image processing tasks, especially with limited data.\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    validation_split=0.2\n)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='training'\n)\nval_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='validation'\n)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T13:57:11.951734Z","iopub.execute_input":"2026-01-07T13:57:11.952234Z","iopub.status.idle":"2026-01-07T13:57:13.658452Z","shell.execute_reply.started":"2026-01-07T13:57:11.952205Z","shell.execute_reply":"2026-01-07T13:57:13.657557Z"}},"outputs":[{"name":"stdout","text":"Found 3788 images belonging to 2 classes.\nFound 945 images belonging to 2 classes.\nFound 1184 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":80},{"id":"3f4b1252","cell_type":"code","source":"# SIMPLE CNN MODEL ARCHITECTURE\n\n# Some modifications are applied\ninitial_learning_rate = 0.001\n# We are combining ExponentialDecay with Adam optimizer for better learning rate management\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=10000,\n    decay_rate=0.9,\n    staircase=True\n)\n\n# Create the optimizer with the learning rate schedule\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n\n# Applied dropout layers to reduce overfitting\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), kernel_regularizer=regularizers.l2(0.001)),\n    layers.MaxPooling2D(2, 2),\n    layers.Dropout(0.25),\n    layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n    layers.MaxPooling2D(2, 2),\n    layers.Dropout(0.25),\n    layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n    layers.MaxPooling2D(2, 2),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n    layers.Dropout(0.5),\n    layers.Dense(1, activation='sigmoid')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T13:57:13.659938Z","iopub.execute_input":"2026-01-07T13:57:13.660631Z","iopub.status.idle":"2026-01-07T13:57:13.739422Z","shell.execute_reply.started":"2026-01-07T13:57:13.660597Z","shell.execute_reply":"2026-01-07T13:57:13.738567Z"}},"outputs":[],"execution_count":81},{"id":"71dcbcb7","cell_type":"code","source":"# Configure the model optimizers, loss function, and metrics\n# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # old\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T13:57:13.741004Z","iopub.execute_input":"2026-01-07T13:57:13.741395Z","iopub.status.idle":"2026-01-07T13:57:13.750615Z","shell.execute_reply.started":"2026-01-07T13:57:13.741354Z","shell.execute_reply":"2026-01-07T13:57:13.749456Z"}},"outputs":[],"execution_count":82},{"id":"750c313f","cell_type":"code","source":"# TRAINING THE CNN\nhistory = model.fit(\n    train_generator,\n    epochs=10,\n    validation_data=val_generator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T13:57:13.752918Z","iopub.execute_input":"2026-01-07T13:57:13.753271Z","iopub.status.idle":"2026-01-07T14:11:57.857650Z","shell.execute_reply.started":"2026-01-07T13:57:13.753243Z","shell.execute_reply":"2026-01-07T14:11:57.856485Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 747ms/step - accuracy: 0.5815 - loss: 1.0407 - val_accuracy: 0.8011 - val_loss: 0.6677\nEpoch 2/10\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 736ms/step - accuracy: 0.7793 - loss: 0.6110 - val_accuracy: 0.7534 - val_loss: 0.6180\nEpoch 3/10\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 740ms/step - accuracy: 0.7964 - loss: 0.5198 - val_accuracy: 0.7577 - val_loss: 0.5755\nEpoch 4/10\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 736ms/step - accuracy: 0.8167 - loss: 0.4884 - val_accuracy: 0.8423 - val_loss: 0.4120\nEpoch 5/10\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 738ms/step - accuracy: 0.8371 - loss: 0.4444 - val_accuracy: 0.8307 - val_loss: 0.4488\nEpoch 6/10\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 740ms/step - accuracy: 0.8278 - loss: 0.4527 - val_accuracy: 0.8635 - val_loss: 0.4012\nEpoch 7/10\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 739ms/step - accuracy: 0.8506 - loss: 0.4130 - val_accuracy: 0.8942 - val_loss: 0.3201\nEpoch 8/10\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 733ms/step - accuracy: 0.8618 - loss: 0.3956 - val_accuracy: 0.8624 - val_loss: 0.4075\nEpoch 9/10\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 737ms/step - accuracy: 0.8397 - loss: 0.4227 - val_accuracy: 0.8974 - val_loss: 0.3296\nEpoch 10/10\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 739ms/step - accuracy: 0.8438 - loss: 0.4334 - val_accuracy: 0.9069 - val_loss: 0.3226\n","output_type":"stream"}],"execution_count":83},{"id":"7541833a","cell_type":"code","source":"# EVALUATE THE MODEL\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(f\"Test Accuracy: {test_acc}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T14:11:57.859001Z","iopub.execute_input":"2026-01-07T14:11:57.859571Z","iopub.status.idle":"2026-01-07T14:12:09.850863Z","shell.execute_reply.started":"2026-01-07T14:11:57.859539Z","shell.execute_reply":"2026-01-07T14:12:09.850038Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 315ms/step - accuracy: 0.8054 - loss: 0.5042\nTest Accuracy: 0.8513513803482056\n","output_type":"stream"}],"execution_count":84},{"id":"2ad7d399","cell_type":"code","source":"# SAVE THE MODEL\nmodel.save('/kaggle/working/models/exercise_6_trained_model_improved.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T14:12:09.852053Z","iopub.execute_input":"2026-01-07T14:12:09.852503Z","iopub.status.idle":"2026-01-07T14:12:09.981465Z","shell.execute_reply.started":"2026-01-07T14:12:09.852461Z","shell.execute_reply":"2026-01-07T14:12:09.980444Z"}},"outputs":[{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"}],"execution_count":85},{"id":"45472d3e","cell_type":"code","source":"# SIMPLE INFERENCE SCRIPT\nfrom tensorflow.keras.preprocessing import image\n\ndef predict_image(img_path, model_path='/kaggle/working/models/exercise_6_trained_model_improved.h5'):\n    model = tf.keras.models.load_model(model_path)\n    img = image.load_img(img_path, target_size=IMG_SIZE)\n    img_array = image.img_to_array(img) / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n    pred = model.predict(img_array)[0,0]\n    label = \"Chihuahua\" if pred >= 0.5 else \"Muffin\"\n    print(f\"Prediction: {label} (confidence: {pred:.2f})\")\n    return pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T14:17:42.715996Z","iopub.execute_input":"2026-01-07T14:17:42.716775Z","iopub.status.idle":"2026-01-07T14:17:42.724260Z","shell.execute_reply.started":"2026-01-07T14:17:42.716734Z","shell.execute_reply":"2026-01-07T14:17:42.722707Z"}},"outputs":[],"execution_count":88},{"id":"b340f1d2","cell_type":"code","source":"# Example usage:\npred1 = predict_image(\"/kaggle/input/muffin-vs-chihuahua-image-classification/test/chihuahua/img_0_1071.jpg\")\npred2 = predict_image(\"/kaggle/input/muffin-vs-chihuahua-image-classification/test/muffin/img_0_105.jpg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T14:17:45.676894Z","iopub.execute_input":"2026-01-07T14:17:45.677261Z","iopub.status.idle":"2026-01-07T14:17:46.335541Z","shell.execute_reply.started":"2026-01-07T14:17:45.677233Z","shell.execute_reply":"2026-01-07T14:17:46.334174Z"}},"outputs":[{"name":"stderr","text":"WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","output_type":"stream"},{"name":"stdout","text":"Prediction: Muffin (confidence: 0.31)\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\nPrediction: Chihuahua (confidence: 0.88)\n","output_type":"stream"}],"execution_count":89},{"id":"66f1b826-b6dd-4d1e-846d-febb0decf78f","cell_type":"markdown","source":"### Accuracy\nTest Accuracy = 85.13%\n\n### Prediction and Confidence\nRun1:<br>\n    Prediction = incorrect<br>\n    Confidence = 0.31<br><br>\nRun2:<br>\n    Prediction = incorrect<br>\n    Confidence = 0.88<br>","metadata":{}}]}