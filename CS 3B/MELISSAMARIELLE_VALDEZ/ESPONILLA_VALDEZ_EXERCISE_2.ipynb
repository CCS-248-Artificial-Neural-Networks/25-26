{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5beb37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 - Hidden Layer 1 (ReLU):\n",
      "  Neuron 1: 1.3900\n",
      "  Neuron 2: 0.0000\n",
      "  Neuron 3: 1.7400\n",
      "\n",
      "Step 2 - Hidden Layer 2 (Sigmoid):\n",
      "  Neuron 1: 0.5297\n",
      "  Neuron 2: 0.5397\n",
      "\n",
      "Step 3 - Output Layer (Softmax probabilities):\n",
      "  Iris-setosa: 0.3081\n",
      "  Iris-versicolor: 0.3813\n",
      "  Iris-virginica: 0.3106\n",
      "\n",
      "Predicted Class: Iris-versicolor\n",
      "Loss: 2.0292\n"
     ]
    }
   ],
   "source": [
    "# Problem A: Iris Dataset\n",
    "import math\n",
    "from helper import weighted_sum, activation_function, calculate_loss\n",
    "\n",
    "# Iris dataset input (Sepal length, Sepal width, Petal length, Petal width)\n",
    "X = [5.1, 3.5, 1.4, 0.2]\n",
    "target_output = [1, 0, 0]  # Iris-setosa (one-hot encoding)\n",
    "\n",
    "# First Hidden Layer (ReLU)\n",
    "W1 = [\n",
    "    [0.2, -0.1, 0.4, 0.3],\n",
    "    [-0.3, 0.2, 0.1, 0.5],\n",
    "    [0.1, 0.4, -0.2, 0.3]\n",
    "]\n",
    "B1 = [0.1, -0.2, 0.05]\n",
    "\n",
    "# Second Hidden Layer (Sigmoid)\n",
    "W2 = [\n",
    "    [0.3, 0.1, -0.2],\n",
    "    [-0.1, 0.4, 0.2]\n",
    "]\n",
    "B2 = [0.05, -0.05]\n",
    "\n",
    "# Output Layer (Softmax)\n",
    "W3 = [\n",
    "    [0.2, -0.1],\n",
    "    [0.1, 0.3],\n",
    "    [-0.2, 0.4]\n",
    "]\n",
    "B3 = [0.0, 0.05, -0.05]\n",
    "\n",
    "# Step 1: First Hidden Layer\n",
    "H1 = []\n",
    "for i in range(len(W1)):\n",
    "    z = weighted_sum(X, W1[i], B1[i])\n",
    "    a = activation_function(z, \"relu\")\n",
    "    H1.append(a)\n",
    "print(\"Step 1 - Hidden Layer 1 (ReLU):\")\n",
    "for idx, val in enumerate(H1, 1):\n",
    "    print(f\"  Neuron {idx}: {val:.4f}\")\n",
    "\n",
    "# Step 2: Second Hidden Layer\n",
    "H2 = []\n",
    "for i in range(len(W2)):\n",
    "    z = weighted_sum(H1, W2[i], B2[i])\n",
    "    a = activation_function(z, \"sigmoid\")\n",
    "    H2.append(a)\n",
    "print(\"\\nStep 2 - Hidden Layer 2 (Sigmoid):\")\n",
    "for idx, val in enumerate(H2, 1):\n",
    "    print(f\"  Neuron {idx}: {val:.4f}\")\n",
    "\n",
    "# Step 3: Output Layer (Softmax)\n",
    "Z3 = []\n",
    "for i in range(len(W3)):\n",
    "    z = weighted_sum(H2, W3[i], B3[i])\n",
    "    Z3.append(z)\n",
    "\n",
    "exp_values = [math.exp(z) for z in Z3]\n",
    "sum_exp = sum(exp_values)\n",
    "softmax_output = [val / sum_exp for val in exp_values]\n",
    "\n",
    "print(\"\\nStep 3 - Output Layer (Softmax probabilities):\")\n",
    "classes = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
    "for cls, val in zip(classes, softmax_output):\n",
    "    print(f\"  {cls}: {val:.4f}\")\n",
    "\n",
    "# Step 4: Predicted Class\n",
    "predicted_class = classes[softmax_output.index(max(softmax_output))]\n",
    "print(f\"\\nPredicted Class: {predicted_class}\")\n",
    "\n",
    "# Step 5: Loss (Cross-Entropy)\n",
    "loss = 0\n",
    "for y_pred, y_true in zip(softmax_output, target_output):\n",
    "    loss += calculate_loss(y_pred, y_true, loss_type=\"cross_entropy\")\n",
    "print(f\"Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8306272f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem B: Breast Cancer Dataset\n",
      "\n",
      "Hidden Layer 1 Output (ReLU):\n",
      "  Neuron 1: 0.9500\n",
      "  Neuron 2: 0.2600\n",
      "\n",
      "Hidden Layer 2 Output (Sigmoid):\n",
      "  Neuron 1: 0.5511\n",
      "  Neuron 2: 0.6608\n",
      "\n",
      "Final Output (Sigmoid):\n",
      "  Predicted probability (Malignant = 1): 0.5658\n",
      "\n",
      "Predicted Class: Malignant (1)\n",
      "\n",
      "Loss:\n",
      "  MSE: 0.1886\n",
      "  Cross-Entropy: 0.5696\n"
     ]
    }
   ],
   "source": [
    "# Problem B: Breast Cancer Dataset\n",
    "import math\n",
    "from helper import weighted_sum, activation_function, calculate_loss\n",
    "\n",
    "# Breast Cancer Dataset inputs (Mean Radius, Mean Texture, Mean Smoothness)\n",
    "X = [14.2, 20.4, 0.10]\n",
    "target_output = [1]  # Malignant\n",
    "\n",
    "# First Hidden Layer (ReLU)\n",
    "W1 = [\n",
    "    [0.2, -0.1, 0.5],\n",
    "    [-0.4, 0.3, 0.2]\n",
    "]\n",
    "B1 = [0.1, -0.2]\n",
    "\n",
    "# Second Hidden Layer (Sigmoid)\n",
    "W2 = [\n",
    "    [0.3, -0.5],\n",
    "    [0.7, 0.2]\n",
    "]\n",
    "B2 = [0.05, -0.05]\n",
    "\n",
    "# Output Layer (Sigmoid, single node)\n",
    "W3 = [[0.6, -0.1]]\n",
    "B3 = [0.0]\n",
    "\n",
    "# Step 1: First Hidden Layer\n",
    "H1 = []\n",
    "for i in range(len(W1)):\n",
    "    z = weighted_sum(X, W1[i], B1[i])\n",
    "    a = activation_function(z, \"relu\")\n",
    "    H1.append(a)\n",
    "\n",
    "print(\"Problem B: Breast Cancer Dataset\\n\")\n",
    "print(\"Hidden Layer 1 Output (ReLU):\")\n",
    "for idx, val in enumerate(H1, 1):\n",
    "    print(f\"  Neuron {idx}: {val:.4f}\")\n",
    "\n",
    "# Step 2: Second Hidden Layer\n",
    "H2 = []\n",
    "for i in range(len(W2)):\n",
    "    z = weighted_sum(H1, W2[i], B2[i])\n",
    "    a = activation_function(z, \"sigmoid\")\n",
    "    H2.append(a)\n",
    "\n",
    "print(\"\\nHidden Layer 2 Output (Sigmoid):\")\n",
    "for idx, val in enumerate(H2, 1):\n",
    "    print(f\"  Neuron {idx}: {val:.4f}\")\n",
    "\n",
    "# Step 3: Output Layer (Sigmoid)\n",
    "Z3 = weighted_sum(H2, W3[0], B3[0])\n",
    "final_output = activation_function(Z3, \"sigmoid\")\n",
    "\n",
    "print(\"\\nFinal Output (Sigmoid):\")\n",
    "print(f\"  Predicted probability (Malignant = 1): {final_output:.4f}\")\n",
    "\n",
    "# Step 4: Predicted Class\n",
    "predicted_class = 1 if final_output >= 0.5 else 0\n",
    "class_name = \"Malignant (1)\" if predicted_class == 1 else \"Benign (0)\"\n",
    "print(f\"\\nPredicted Class: {class_name}\")\n",
    "\n",
    "# Step 5: Loss\n",
    "mse_loss = calculate_loss(final_output, target_output[0], loss_type=\"mse\")\n",
    "ce_loss = calculate_loss(final_output, target_output[0], loss_type=\"cross_entropy\")\n",
    "\n",
    "print(\"\\nLoss:\")\n",
    "print(f\"  MSE: {mse_loss:.4f}\")\n",
    "print(f\"  Cross-Entropy: {ce_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
