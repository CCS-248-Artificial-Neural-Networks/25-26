{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0489dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Load the required library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623b430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define Dense_Layer class and activation functions\n",
    "class Dense_Layer:\n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.activation = None\n",
    "        self.output = None\n",
    "\n",
    "    def setup(self, inputs, weights, bias, activation):\n",
    "        \"\"\"Accept and set up inputs, weights, bias, and activation function.\"\"\"\n",
    "        self.inputs = np.array(inputs)\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "        self.activation = activation\n",
    "\n",
    "    def weighted_sum(self):\n",
    "        \"\"\"Perform weighted sum + bias.\"\"\"\n",
    "        return np.dot(self.inputs, self.weights) + self.bias\n",
    "\n",
    "    def activate(self, x):\n",
    "        \"\"\"Apply the selected activation function.\"\"\"\n",
    "        if self.activation == 'relu':\n",
    "            return np.maximum(0, x)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        elif self.activation == 'softmax':\n",
    "            exp_x = np.exp(x - np.max(x))\n",
    "            return exp_x / exp_x.sum(axis=-1, keepdims=True)\n",
    "        else:\n",
    "            raise ValueError('Unsupported activation function')\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"Complete forward pass: weighted sum + activation.\"\"\"\n",
    "        z = self.weighted_sum()\n",
    "        self.output = self.activate(z)\n",
    "        return self.output\n",
    "\n",
    "    def loss(self, target):\n",
    "        \"\"\"Calculate categorical cross-entropy loss.\"\"\"\n",
    "        predicted = np.array(self.output)\n",
    "        target = np.array(target)\n",
    "        predicted = np.clip(predicted, 1e-9, 1 - 1e-9)\n",
    "        return -np.sum(target * np.log(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d95716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Input values for the Iris problem\n",
    "iris_input = [5.1, 3.5, 1.4, 0.2]  # Sepal length, sepal width, petal length, petal width\n",
    "target_output = [0.7, 0.2, 0.1]     # Example target (can be one-hot for true label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46965d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First layer output (ReLU): [3.93 0.15 0.85]\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: First hidden layer (ReLU activation)\n",
    "# Weights and bias for first layer\n",
    "W1 = [[0.2, 0.5, -0.3],\n",
    "      [0.1, -0.2, 0.4],\n",
    "      [-0.4, 0.3, 0.2],\n",
    "      [0.6, -0.1, 0.5]]\n",
    "B1 = [3.0, -2.1, 0.6]\n",
    "\n",
    "layer1 = Dense_Layer()\n",
    "layer1.setup(iris_input, W1, B1, 'relu')\n",
    "out1 = layer1.forward()\n",
    "print('First layer output (ReLU):', out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c37d02a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second layer output (Sigmoid): [0.99378157 0.99187781]\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Second hidden layer (Sigmoid activation)\n",
    "# Weights and bias for second layer\n",
    "W2 = [[0.3, -0.5],\n",
    "      [0.7, 0.2],\n",
    "      [-0.6, 0.4]]\n",
    "B2 = [4.3, 6.4]\n",
    "\n",
    "layer2 = Dense_Layer()\n",
    "layer2.setup(out1, W2, B2, 'sigmoid')\n",
    "out2 = layer2.forward()\n",
    "print('Second layer output (Sigmoid):', out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2c8d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layer (Softmax): [0.0265075  0.96865119 0.00484132]\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Output layer (Softmax activation)\n",
    "# Weights and bias for output layer\n",
    "W3 = [[0.5, -0.3, 0.8],\n",
    "      [-0.2, 0.6, -0.4]]\n",
    "B3 = [-1.5, 2.1, -3.3]\n",
    "\n",
    "layer3 = Dense_Layer()\n",
    "layer3.setup(out2, W3, B3, 'softmax')\n",
    "output = layer3.forward()\n",
    "print('Output layer (Softmax):', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "042e1ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Forward pass (all layers) and predicted class\n",
    "classes = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "predicted_class = np.argmax(output)\n",
    "print('Predicted class:', classes[predicted_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae65a7dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categorical_crossentropy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 8: Loss function (Categorical cross-entropy)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m loss = \u001b[43mcategorical_crossentropy\u001b[49m(output, target_output)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mCategorical cross-entropy loss:\u001b[39m\u001b[33m'\u001b[39m, loss)\n",
      "\u001b[31mNameError\u001b[39m: name 'categorical_crossentropy' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 8: Loss function (Categorical cross-entropy)\n",
    "loss = layer3.loss(target_output)\n",
    "print('Categorical cross-entropy loss:', loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
