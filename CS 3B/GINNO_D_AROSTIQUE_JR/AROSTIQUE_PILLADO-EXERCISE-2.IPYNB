{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0489dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "623b430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense_Layer class with methods for setup, forward pass, and loss calculation\n",
    "class Dense_Layer:\n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.activation = None\n",
    "        self.output = None\n",
    "\n",
    "    def setup(self, inputs, weights, bias, activation):\n",
    "        \"Accept and set up inputs, weights, bias, and activation function.\"\n",
    "        self.inputs = np.array(inputs)\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "        self.activation = activation\n",
    "\n",
    "    def weighted_sum(self):\n",
    "        \"Perform weighted sum + bias.\"\n",
    "        return np.dot(self.inputs, self.weights) + self.bias\n",
    "\n",
    "    def activate(self, x):\n",
    "        \"Apply the selected activation function.\"\n",
    "        #ReLU Function\n",
    "        if self.activation == 'relu':\n",
    "            return np.maximum(0, x)\n",
    "        #Sigmoid Function\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        #Softmax Function\n",
    "        elif self.activation == 'softmax':\n",
    "            exp_x = np.exp(x - np.max(x))\n",
    "            return exp_x / exp_x.sum(axis=-1, keepdims=True)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('Invalid Activation Function')\n",
    "\n",
    "    def forward(self):\n",
    "        \"Complete forward pass: weighted sum + activation.\"\n",
    "        z = self.weighted_sum()\n",
    "        self.output = self.activate(z)\n",
    "        return self.output\n",
    "\n",
    "    def loss(self, target):\n",
    "        \"Calculate categorical cross-entropy loss.\"\n",
    "        predicted = np.array(self.output)\n",
    "        target = np.array(target)\n",
    "        predicted = np.clip(predicted, 1e-9, 1 - 1e-9)\n",
    "        return -np.sum(target * np.log(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31d95716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input values for the Iris\n",
    "iris_input = [5.1, 3.5, 1.4, 0.2]  # Parameters: sepal length, sepal width, petal length, petal width\n",
    "target_output = [0.7, 0.2, 0.1]    # Target output for the three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46965d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First layer weighted sum: [3.93 0.15 0.85]\n",
      "\n",
      "First layer output (ReLU): [3.93 0.15 0.85]\n"
     ]
    }
   ],
   "source": [
    "# First hidden layer (ReLU activation)\n",
    "# Weights and bias for first layer\n",
    "W1 = [[0.2, 0.5, -0.3],\n",
    "      [0.1, -0.2, 0.4],\n",
    "      [-0.4, 0.3, 0.2],\n",
    "      [0.6, -0.1, 0.5]]\n",
    "\n",
    "B1 = [3.0, -2.1, 0.6]\n",
    "\n",
    "layer1 = Dense_Layer()\n",
    "layer1.setup(iris_input, W1, B1, 'relu')\n",
    "\n",
    "#Weighted sum\n",
    "z1 = layer1.weighted_sum()\n",
    "print('First layer weighted sum:', z1)\n",
    "\n",
    "#Activation function\n",
    "output1 = layer1.activate(z1)\n",
    "print('\\nFirst layer output (ReLU):', output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d02a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second layer weighted sum: [5.074 4.805]\n",
      "\n",
      "Second layer output (Sigmoid): [0.99378157 0.99187781]\n"
     ]
    }
   ],
   "source": [
    "# Second hidden layer (Sigmoid activation)\n",
    "# Weights and bias for second layer\n",
    "W2 = [[0.3, -0.5],\n",
    "      [0.7, 0.2],\n",
    "      [-0.6, 0.4]]\n",
    "\n",
    "B2 = [4.3, 6.4]\n",
    "\n",
    "layer2 = Dense_Layer()\n",
    "layer2.setup(output1, W2, B2, 'sigmoid')\n",
    "\n",
    "#Weighted sum\n",
    "z2 = layer2.weighted_sum()\n",
    "print('Second layer weighted sum:', z2)\n",
    "\n",
    "#Activation function\n",
    "output2 = layer2.activate(z2)\n",
    "print('\\nSecond layer output (Sigmoid):', output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c8d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layer weighted sum: [-1.20148478  2.39699221 -2.90172587]\n",
      "\n",
      "Output layer (Softmax): [0.0265075  0.96865119 0.00484132]\n",
      "\n",
      "Probability distribution (%):  [ 2.65074966 96.86511878  0.48413156]\n"
     ]
    }
   ],
   "source": [
    "# Output layer (Softmax activation)\n",
    "# Weights and bias for output layer\n",
    "W3 = [[0.5, -0.3, 0.8],\n",
    "      [-0.2, 0.6, -0.4]]\n",
    "\n",
    "B3 = [-1.5, 2.1, -3.3]\n",
    "\n",
    "layer3 = Dense_Layer()\n",
    "layer3.setup(out2, W3, B3, 'softmax')\n",
    "\n",
    "#Weighted sum\n",
    "z3 = layer3.weighted_sum()\n",
    "print('Output layer weighted sum:', z3)\n",
    "\n",
    "#Activation function\n",
    "output = layer3.forward()\n",
    "print('\\nOutput layer (Softmax):', output)\n",
    "\n",
    "#Neural network Output\n",
    "probability_distribution = output * 100 \n",
    "print('\\nProbability distribution (%): ', probability_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae65a7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical cross-entropy loss: 3.080656405230887\n"
     ]
    }
   ],
   "source": [
    "# Loss function (Categorical cross-entropy)\n",
    "loss = layer3.loss(target_output)\n",
    "print('Categorical cross-entropy loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0af09fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "IRIS SPECIES CLASSIFICATION RESULTS\n",
      "======================================================================\n",
      "Input measurements (sepal length, sepal width, petal length, petal width):\n",
      "  iris_input = [5.1, 3.5, 1.4, 0.2]\n",
      "Target output (probabilities for each species):\n",
      "  [0.7, 0.2, 0.1]\n",
      "\n",
      "Predicted probabilities for each species:\n",
      "  Iris-setosa: 0.0265 (2.65%)\n",
      "  Iris-versicolor: 0.9687 (96.87%)\n",
      "  Iris-virginica: 0.0048 (0.48%)\n",
      "\n",
      "Classification Result:\n",
      "  Predicted Species: Iris-versicolor\n",
      "  Confidence: 0.9687 (96.87%)\n",
      "\n",
      "Loss Function (Categorical Cross-Entropy):\n",
      "  Loss: 3.0807\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"IRIS SPECIES CLASSIFICATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Input measurements and target output\n",
    "print(f\"Input measurements (sepal length, sepal width, petal length, petal width):\")\n",
    "print(f\"  iris_input = {iris_input}\")\n",
    "print(f\"Target output (probabilities for each species):\")\n",
    "print(f\"  {target_output}\")\n",
    "\n",
    "# Predicted probabilities for each species\n",
    "iris_species = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "print(\"\\nPredicted probabilities for each species:\")\n",
    "for i, species in enumerate(iris_species):\n",
    "    print(f\"  {species}: {output[i]:.4f} ({output[i]*100:.2f}%)\")\n",
    "\n",
    "# Classification result\n",
    "predicted_class_index = np.argmax(output)\n",
    "predicted_species = iris_species[predicted_class_index]\n",
    "predicted_probability = output[predicted_class_index]\n",
    "print(\"\\nClassification Result:\")\n",
    "print(f\"  Predicted Species: {predicted_species}\")\n",
    "print(f\"  Confidence: {predicted_probability:.4f} ({predicted_probability*100:.2f}%)\")\n",
    "\n",
    "# Present the loss function\n",
    "print(\"\\nLoss Function (Categorical Cross-Entropy):\")\n",
    "print(f\"  Loss: {loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
