{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cfc5a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (8, 7) -> Output: 1\n",
      "Input (3, 4) -> Output: 0\n"
     ]
    }
   ],
   "source": [
    "def perceptron(\n",
    "    x1, x2,\n",
    "    w1=0.6, w2=0.4,\n",
    "    bias=-3,\n",
    "    threshold=1):\n",
    "    #weighted_sum\n",
    "    total = w1 * x1 + w2 * x2 + bias\n",
    "    #step_function\n",
    "    return 1 if total >= threshold else 0\n",
    "\n",
    "#test_inputs\n",
    "inputs = [(8, 7), (3, 4)]\n",
    "\n",
    "for x1, x2 in inputs:\n",
    "    output = perceptron(x1, x2)\n",
    "    print(f\"Input ({x1}, {x2}) -> Output: {output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c43a38d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 2 - Logic Gate Simulation (AND Gate)\n",
      "\n",
      "Input: (0, 0)\n",
      "Output: 0\n",
      "Output with bias: -1.5\n",
      "Activation: 0 \n",
      "\n",
      "Input: (0, 1)\n",
      "Output: 1\n",
      "Output with bias: -0.5\n",
      "Activation: 0 \n",
      "\n",
      "Input: (1, 0)\n",
      "Output: 1\n",
      "Output with bias: -0.5\n",
      "Activation: 0 \n",
      "\n",
      "Input: (1, 1)\n",
      "Output: 2\n",
      "Output with bias: 0.5\n",
      "Activation: 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# No. 2 - Logic Gate Simulation (AND Gate)\n",
    "inputs2 = [(0,0), (0,1), (1,0), (1,1)]\n",
    "weights2 = [1, 1]\n",
    "bias2 = -1.5\n",
    "\n",
    "# threshold = 0\n",
    "def step_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "print(\"No. 2 - Logic Gate Simulation (AND Gate)\\n\")\n",
    "\n",
    "for x in inputs2:\n",
    "    output = 0\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        output += x[i] * weights2[i]\n",
    "    \n",
    "    print(\"Input:\", x)\n",
    "    print(\"Output:\", output)\n",
    "    \n",
    "    output_with_bias = output + bias2\n",
    "    print(\"Output with bias:\", output_with_bias)\n",
    "    \n",
    "    activated = step_function(output_with_bias)\n",
    "    print(\"Activation:\", activated, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02348aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of A:  1.5\n",
      "Output with Bias:  1.7\n",
      "Activation:  True\n",
      "Output of B:  0.5\n",
      "Output with Bias:  0.5\n",
      "Activation:  True\n",
      "Output of C:  0.75\n",
      "Output with Bias:  0.15000000000000002\n",
      "Activation:  True\n",
      "Winner is output A\n"
     ]
    }
   ],
   "source": [
    "#3.\t(60 points) Perceptron comparison (One vs All).\n",
    "#  Given the 3 perceptron, using the same input, \n",
    "# compute the output and decided on the predicted class is the WINNER.\n",
    "#  If a tie is present, compare and get the highest weighted sum. \n",
    "\n",
    "#################################################################333\n",
    "\n",
    "inputs = [0.5, -1, 2, 1, 0]\n",
    "weights_A = [1.0, -0.5, 0.2, 0.1, 0.0]\n",
    "weights_B = [0.2, 0.2, 0.5, -0.4, 0.3]\n",
    "weights_C = [-0.3, -0.1, 0.4, 0.0, 0.2]\n",
    "bias_A = 0.2\n",
    "bias_B = 0.0\n",
    "bias_C = -0.6\n",
    "\n",
    "output_A = 0\n",
    "output_B = 0\n",
    "output_C = 0\n",
    "\n",
    "######################### A ##################\n",
    "for i in range(len(inputs)):\n",
    "    output_A += inputs[i] * weights_A[i]\n",
    "\n",
    "print(\"Output of A: \", output_A)\n",
    "\n",
    "output_A += bias_A\n",
    "print(\"Output with Bias: \", output_A)\n",
    "\n",
    "activate = output_A > 0\n",
    "print(\"Activation: \", activate)\n",
    "\n",
    "######################### B ##################\n",
    "for i in range(len(inputs)):\n",
    "    output_B += inputs[i] * weights_B[i]\n",
    "\n",
    "print(\"Output of B: \", output_B)\n",
    "\n",
    "output_B += bias_B\n",
    "print(\"Output with Bias: \", output_B)\n",
    "\n",
    "activate = output_B > 0\n",
    "print(\"Activation: \", activate)\n",
    "\n",
    "################## C ######################\n",
    "for i in range(len(inputs)):\n",
    "    output_C += inputs[i] * weights_C[i]\n",
    "\n",
    "print(\"Output of C: \", output_C)\n",
    "\n",
    "output_C += bias_C\n",
    "print(\"Output with Bias: \", output_C)\n",
    "\n",
    "activate = output_C > 0\n",
    "print(\"Activation: \", activate)\n",
    "\n",
    "\n",
    "############### Winner #################\n",
    "\n",
    "if output_A > output_B and output_A > output_C:\n",
    "    print(\"Winner is output A\")\n",
    "elif output_B > output_A and output_B > output_C:\n",
    "    print(\"Winner is output B\")\n",
    "elif output_C > output_A and output_C > output_B:\n",
    "    print(\"Winner is output C\")\n",
    "else:\n",
    "    \n",
    "    sum_A = sum([inputs[i] * weights_A[i] for i in range(len(inputs))])\n",
    "    sum_B = sum([inputs[i] * weights_B[i] for i in range(len(inputs))])\n",
    "    sum_C = sum([inputs[i] * weights_C[i] for i in range(len(inputs))])\n",
    "\n",
    "    max_sum = max(sum_A, sum_B, sum_C)\n",
    "    if max_sum == sum_A:\n",
    "        print(\"Winner is output A (by weighted sum)\")\n",
    "    elif max_sum == sum_B:\n",
    "        print(\"Winner is output B (by weighted sum)\")\n",
    "    else:\n",
    "        print(\"Winner is output C (by weighted sum)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
