{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea8a7d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ddd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_Layer:\n",
    "    def __init__(self, weights, biases, activation=\"relu\"):\n",
    "        self.weights = np.array(weights, dtype=float)\n",
    "        self.biases = np.array(biases, dtype=float)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = np.array(inputs, dtype=float)\n",
    "        z = self.weights.dot(x) + self.biases\n",
    "        a = self._activate(z)\n",
    "        return z, a\n",
    "\n",
    "    def _activate(self, z):\n",
    "        if self.activation == \"relu\":\n",
    "            return np.maximum(0, z)\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            return 1.0 / (1.0 + np.exp(-z))\n",
    "        elif self.activation == \"softmax\":\n",
    "            exp_vals = np.exp(z - np.max(z))\n",
    "            return exp_vals / np.sum(exp_vals)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation: \" + str(self.activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "833bed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add_layer(self, weights, biases, activation=\"relu\"):\n",
    "        self.layers.append(Dense_Layer(weights, biases, activation))\n",
    "\n",
    "    def forward_pass(self, inputs, verbose=False, round_digits=4):\n",
    "        x = np.array(inputs, dtype=float)\n",
    "        intermediates = []\n",
    "        for i, layer in enumerate(self.layers, start=1):\n",
    "            z, a = layer.forward(x)\n",
    "            intermediates.append({\"z\": z, \"a\": a, \"activation\": layer.activation})\n",
    "            if verbose:\n",
    "                print(f\"  Layer {i} (activation={layer.activation})\")\n",
    "                print(\"    Z =\", np.round(z, round_digits))\n",
    "                print(\"    A =\", np.round(a, round_digits))\n",
    "            x = a\n",
    "        return intermediates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4573f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "def categorical_cross_entropy(y_pred, y_true):\n",
    "    eps = 1e-15\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    return -np.sum(np.array(y_true) * np.log(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5aa061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_pred, y_true):\n",
    "    eps = 1e-15\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    return - (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d310b4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Problem A>\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m model = NeuralNetwork()\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# First hidden layer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m             \u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m             \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbiases\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Second hidden layer\u001b[39;00m\n\u001b[32m     20\u001b[39m model.add_layer(\n\u001b[32m     21\u001b[39m     weights=[[\u001b[32m0.3\u001b[39m, -\u001b[32m0.5\u001b[39m, \u001b[32m0.7\u001b[39m],\n\u001b[32m     22\u001b[39m              [\u001b[32m0.2\u001b[39m, -\u001b[32m0.6\u001b[39m, \u001b[32m0.4\u001b[39m]],\n\u001b[32m     23\u001b[39m     biases=[\u001b[32m4.3\u001b[39m, \u001b[32m6.4\u001b[39m],\n\u001b[32m     24\u001b[39m     activation=\u001b[33m\"\u001b[39m\u001b[33msigmoid\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mNeuralNetwork.add_layer\u001b[39m\u001b[34m(self, weights, biases, activation)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_layer\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights, biases, activation=\u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28mself\u001b[39m.layers.append(\u001b[43mDense_Layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbiases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mDense_Layer.__init__\u001b[39m\u001b[34m(self, weights, biases, activation)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights, biases, activation=\u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28mself\u001b[39m.weights = \u001b[43mnp\u001b[49m.array(weights, dtype=\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mself\u001b[39m.biases = np.array(biases, dtype=\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mself\u001b[39m.activation = activation\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # -----------------------\n",
    "    # ARIANE: Problem A (Iris dataset)\n",
    "    # -----------------------\n",
    "    print(\"<Problem A>\")\n",
    "    print(\"-\" * 40)\n",
    "    X = [5.1, 3.5, 1.4, 0.2]\n",
    "    target = [0.7, 0.2, 0.1]\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "    # First hidden layer\n",
    "    model.add_layer(\n",
    "        weights=[[0.2, 0.5, -0.3, 0.1],\n",
    "                 [-0.2, 0.4, -0.4, 0.3],\n",
    "                 [0.2, 0.6, -0.1, 0.5]],\n",
    "        biases=[3.0, -2.1, 0.6],\n",
    "        activation=\"relu\"\n",
    "    )\n",
    "    # Second hidden layer\n",
    "    model.add_layer(\n",
    "        weights=[[0.3, -0.5, 0.7],\n",
    "                 [0.2, -0.6, 0.4]],\n",
    "        biases=[4.3, 6.4],\n",
    "        activation=\"sigmoid\"\n",
    "    )\n",
    "    # Output layer\n",
    "    model.add_layer(\n",
    "        weights=[[0.5, -0.3],\n",
    "                 [0.8, -0.2],\n",
    "                 [0.6, -0.4]],\n",
    "        biases=[-1.5, 2.1, -3.3],\n",
    "        activation=\"softmax\"\n",
    "    )\n",
    "\n",
    "    results = model.forward_pass(X, verbose=True, round_digits=4)\n",
    "    print(\"\\nHidden Layer 2 (Output):\", np.round(results[1][\"a\"], 4))\n",
    "    final_output = results[-1][\"a\"]\n",
    "    print(\"Final Output (Softmax):\", np.round(final_output, 6))\n",
    "\n",
    "    classes = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
    "    print(\"Predicted Class:\", classes[int(np.argmax(final_output))])\n",
    "    loss = categorical_cross_entropy(final_output, target)\n",
    "    print(\"Loss:\", round(loss, 6))\n",
    "    print(\"-\" * 40, \"\\n\")\n",
    "\n",
    "    # -----------------------\n",
    "    # LEANN: Problem B (Breast Cancer dataset)\n",
    "    # -----------------------\n",
    "    print(\"<Problem B>\")\n",
    "    print(\"-\" * 40)\n",
    "    Xb = [14.1, 20.3, 0.095]\n",
    "    target_b = 1.0  # malignant\n",
    "\n",
    "    model_b = NeuralNetwork()\n",
    "    # First hidden layer\n",
    "    model_b.add_layer(\n",
    "        weights=[[0.5, -0.3, 0.8],\n",
    "                 [0.2, 0.4, -0.6],\n",
    "                 [-0.7, 0.9, 0.1]],\n",
    "        biases=[0.3, -0.5, 0.6],\n",
    "        activation=\"relu\"\n",
    "    )\n",
    "    # Second hidden layer\n",
    "    model_b.add_layer(\n",
    "        weights=[[0.6, -0.2, 0.4],\n",
    "                 [-0.3, 0.5, 0.7]],\n",
    "        biases=[0.1, -0.8],\n",
    "        activation=\"sigmoid\"\n",
    "    )\n",
    "    # Output layer\n",
    "    model_b.add_layer(\n",
    "        weights=[[0.7, -0.5]],\n",
    "        biases=[0.2],\n",
    "        activation=\"sigmoid\"\n",
    "    )\n",
    "\n",
    "    results_b = model_b.forward_pass(Xb, verbose=True, round_digits=4)\n",
    "    print(\"\\nHidden Layer 2 (Output):\", np.round(results_b[1][\"a\"], 4))\n",
    "    final_output_b = results_b[-1][\"a\"].item()\n",
    "    print(\"Final Output (Sigmoid):\", round(final_output_b, 6))\n",
    "\n",
    "    pred_label = 1 if final_output_b >= 0.5 else 0\n",
    "    print(\"Predicted Class:\", \"Malignant (1)\" if pred_label == 1 else \"Benign (0)\")\n",
    "    loss_b = binary_cross_entropy(final_output_b, target_b)\n",
    "    print(\"Loss:\", round(loss_b, 6))\n",
    "    print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
