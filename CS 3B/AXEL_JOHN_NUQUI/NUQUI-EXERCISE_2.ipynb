{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "394f5be5",
   "metadata": {},
   "source": [
    "IMPORT NEEDED DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1708b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network_helper import setup_inputs_weights, calculate_loss, calculate_ws, calculate_relu, calculate_sigmoid, calculate_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53326fa",
   "metadata": {},
   "source": [
    "2a.\tGiven the following inputs from the Iris Dataset, using the sepal length, sepal width, petal length and petal width, determine what class (Iris-setosa, Iris-versicolor, and Iris-virginica) the following inputs are by calculating the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa59bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Hidden Layer Outputs: [3.93 0.15 0.85]\n"
     ]
    }
   ],
   "source": [
    "# First Hidden Layer Calculation\n",
    "inputs1 = [5.1, 3.5, 1.4, 0.2]\n",
    "target_output = [0.7, 0.2, 0.1]\n",
    "weights1 = [\n",
    "    [0.2, 0.5, -0.3],\n",
    "    [0.1, -0.2, 0.4],\n",
    "    [-0.4, 0.3, 0.2],\n",
    "    [0.6, -0.1, 0.5]\n",
    "]\n",
    "biases1 = [3.0, -2.1, 0.6]\n",
    "\n",
    "setup_inputs_weights(inputs1, weights1)\n",
    "layer1_output = calculate_ws(inputs1, weights1, biases1)\n",
    "\n",
    "print(f'First Hidden Layer Outputs: {layer1_output}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71f0c6",
   "metadata": {},
   "source": [
    "CALCULATING THE ACTIVATION FUNCTION USING RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6152ce56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Layer Inputs (after ReLu): [3.93, 0.15, 0.85]\n"
     ]
    }
   ],
   "source": [
    "inputs2 = calculate_relu(layer1_output)\n",
    "inputs2 = [float(round(x, 2)) for x in inputs2]\n",
    "print(\"Second Layer Inputs (after ReLu):\", inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e20d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Hidden Layer Outputs: [5.074 4.805]\n"
     ]
    }
   ],
   "source": [
    "weights2 = [\n",
    "    [0.3, -0.5],\n",
    "    [0.7, 0.2],\n",
    "    [-0.6, 0.4]\n",
    "]\n",
    "biases2 = [4.3, 6.4]\n",
    "\n",
    "inputs2, weights2 = setup_inputs_weights(inputs2, weights2)\n",
    "layer2_outputs = calculate_ws(inputs2, weights2, biases2)\n",
    "print(f'Second Hidden Layer Outputs: {layer2_outputs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be373b57",
   "metadata": {},
   "source": [
    "CALCULATION OF ACTIVATION FUNCTION USING SIGMOID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ae6f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Layer Inputs (after Sigmoid) [0.99, 0.99]\n"
     ]
    }
   ],
   "source": [
    "inputs3 = calculate_sigmoid(layer2_outputs)\n",
    "inputs3 = [float(round(x, 2)) for x in inputs3]\n",
    "\n",
    "print(\"Last Layer Inputs (after Sigmoid)\", inputs3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdbcb47",
   "metadata": {},
   "source": [
    "CALCULATION OF THE LAST LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0fa797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Layer Outputs: [-1.203  2.397 -2.904]\n"
     ]
    }
   ],
   "source": [
    "weights3 = [\n",
    "    [0.5, -0.3, 0.8],\n",
    "    [-0.2, 0.6, -0.4]\n",
    "]\n",
    "biases3 = [-1.5, 2.1, -3.3]\n",
    "\n",
    "inputs3, weights3 = setup_inputs_weights(inputs3, weights3)\n",
    "last_layer_outputs = calculate_ws(inputs3, weights3, biases3)\n",
    "\n",
    "print(f'Last Layer Outputs: {last_layer_outputs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af632afc",
   "metadata": {},
   "source": [
    "CALCULATING THE ACTIVATION FUNCTION USING SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63521de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Layer's Activation Function (after Softmax):  [0.03, 0.97, 0.0]\n"
     ]
    }
   ],
   "source": [
    "last_layer_af = calculate_softmax(last_layer_outputs)\n",
    "last_layer_af = [float(round(x, 2)) for x in last_layer_af]\n",
    "\n",
    "print(\"Last Layer's Activation Function (after Softmax): \", last_layer_af)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cca0eb",
   "metadata": {},
   "source": [
    "CALCULATING LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53169322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.9146\n"
     ]
    }
   ],
   "source": [
    "loss = calculate_loss(target_output, last_layer_af)\n",
    "print(f'Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fddd7d6",
   "metadata": {},
   "source": [
    "Hidden Layer 2 (Output): [5.074 4.805]\n",
    "Loss: 5.9146"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
