{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5b6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We've considered making the code into two(2) functions: \"run_perceptron_inputs\" and \"run_perceptron_weights\"\n",
    "#to call either different inputs, weights and biases later for code reusability and especially, avoid redundancy\n",
    "\n",
    "#We've also included the \"label parameter for labelling sub-numbers(answers), and \"threshold parameter\" so we could reedit the\n",
    "#activation values unique to each number\n",
    "\n",
    "#function call specifically for NO.1 and NO.2, already provided weights and biases but inputs are susceptible for change\n",
    "def run_perceptron_inputs(inputs_list, weights, bias, label=\"\", threshold=\"\"):\n",
    "    if label:\n",
    "        print(f\"Answers for {label}:\")\n",
    "    \n",
    "    for idx, inputs in enumerate(inputs_list, start=1):\n",
    "        print(f\"Sub-Answer {idx}:\")\n",
    "        \n",
    "        output = 0\n",
    "        for i in range(len(inputs)):\n",
    "            output += inputs[i] * weights[i]\n",
    "\n",
    "        print(\"  Output:\", output)\n",
    "\n",
    "        output += bias\n",
    "        print(\"  Output with bias:\", output)\n",
    "\n",
    "        activate = output > threshold\n",
    "        print(f\"  Activation (threshold={threshold}):\", activate)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9c6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function call specifically for NO.3, already provided inputs but weights and biases are susceptible for change\n",
    "def run_perceptron_weights(inputs, weights_bias_list, label=\"\", threshold=\"\"):\n",
    "    if label:\n",
    "        print(f\"Answer for {label}\")\n",
    "    \n",
    "    outputs = []\n",
    "    activations = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, (weights, bias) in enumerate(weights_bias_list, start=1):\n",
    "        letter = chr(64 + idx) #for conversion to letters\n",
    "        print(f\" Perceptron {letter}:\")\n",
    "        \n",
    "        output = 0\n",
    "        for i in range(len(inputs)):\n",
    "            output += inputs[i] * weights[i]\n",
    "\n",
    "        print(\"  Output:\", output)\n",
    "\n",
    "        output += bias\n",
    "        print(\"  Output with bias:\", output)\n",
    "\n",
    "        activate = output > threshold\n",
    "        print(f\"  Activation (threshold={threshold}):\", activate)\n",
    "        print()\n",
    "\n",
    "        outputs.append(output)\n",
    "        activations.append(activate)\n",
    "        labels.append(letter)\n",
    "\n",
    "\n",
    "    #Final Decision for (One vs All)\n",
    "    print(\"Final Decision:\")\n",
    "\n",
    "    if all(act == activations[0] for act in activations):\n",
    "        #When all activations are the same, pick highest weighted sum\n",
    "        max_index = outputs.index(max(outputs))\n",
    "        winner = labels[max_index]\n",
    "    else:\n",
    "        #If only one activated, thatâ€™s the winner\n",
    "        if activations.count(True) == 1:\n",
    "            winner = labels[activations.index(True)]\n",
    "        else:\n",
    "            #Tie, then pick highest weighted sum\n",
    "            max_index = outputs.index(max(outputs))\n",
    "            winner = labels[max_index]\n",
    "\n",
    "    print(\"Predicted Class (Winner): Perceptron\", winner)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3627c859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers for No.1:\n",
      "Sub-Answer 1:\n",
      "  Output: 7.6\n",
      "  Output with bias: 4.6\n",
      "  Activation (threshold=1): True\n",
      "\n",
      "Sub-Answer 2:\n",
      "  Output: 3.4\n",
      "  Output with bias: 0.3999999999999999\n",
      "  Activation (threshold=1): False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#No.1: Determine whether the student passes (1) or fails (0) based on: A) Hours studied and B) Hours of Sleep\n",
    "#provided weights and biases for number 1\n",
    "weights1 = [0.6, 0.4]\n",
    "bias1 = -3\n",
    "\n",
    "inputs_group1 = [\n",
    "    [8, 7],  #1A: Hours Studied\n",
    "    [3, 4]   #1B: Hours of Sleep\n",
    "]\n",
    "\n",
    "run_perceptron_inputs (inputs_group1, weights1, bias1, label=\"No.1\", threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97fabdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers for No.2:\n",
      "Sub-Answer 1:\n",
      "  Output: 0\n",
      "  Output with bias: -1.5\n",
      "  Activation (threshold=0): False\n",
      "\n",
      "Sub-Answer 2:\n",
      "  Output: 1\n",
      "  Output with bias: -0.5\n",
      "  Activation (threshold=0): False\n",
      "\n",
      "Sub-Answer 3:\n",
      "  Output: 1\n",
      "  Output with bias: -0.5\n",
      "  Activation (threshold=0): False\n",
      "\n",
      "Sub-Answer 4:\n",
      "  Output: 2\n",
      "  Output with bias: 0.5\n",
      "  Activation (threshold=0): True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#No.2: Logic Gate Simulation. Given the following setup for a perceptron, compute its output and verify whether it acts as an AND gate: \n",
    "#provided weights and biases for number 2\n",
    "weights2 = [1, 1]\n",
    "bias2 = -1.5\n",
    "\n",
    "inputs_group2 = [\n",
    "    [0, 0],  #first inputs\n",
    "    [0, 1],  #2nd\n",
    "    [1, 0],  #3rd\n",
    "    [1, 1]   #last inputs\n",
    "]\n",
    "\n",
    "run_perceptron_inputs (inputs_group2, weights2, bias2, label=\"No.2\", threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5b6805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer for No. 3\n",
      " Perceptron A:\n",
      "  Output: 1.5\n",
      "  Output with bias: 1.7\n",
      "  Activation (threshold=0): True\n",
      "\n",
      " Perceptron B:\n",
      "  Output: 0.5\n",
      "  Output with bias: 0.5\n",
      "  Activation (threshold=0): True\n",
      "\n",
      " Perceptron C:\n",
      "  Output: 0.75\n",
      "  Output with bias: 0.15000000000000002\n",
      "  Activation (threshold=0): True\n",
      "\n",
      "Final Decision:\n",
      "Predicted Class (Winner): Perceptron A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#No.3: Perceptron comparison (One vs All). Given the 3 perceptron, using the same input, compute the output and decided\n",
    "#on the predicted class is the WINNER. If a tie is present, compare and get the highest weighted sum.\n",
    "\n",
    "#provided inputs for Number 3 (applies to the three perceptrons)\n",
    "inputs = [0.5, -1, 2, 1, 0]\n",
    "weights_bias_group = [                    \n",
    "    ([1.0, -0.5, 0.2, 0.1, 0.0], 0.2),\n",
    "    ([0.2, 0.2, 0.5, -0.4, 0.3], 0.0),\n",
    "    ([-0.3, -0.1, 0.4, 0.0, 0.2], -0.6)\n",
    "]\n",
    "\n",
    "run_perceptron_weights(inputs, weights_bias_group, label=\"No. 3\", threshold=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
