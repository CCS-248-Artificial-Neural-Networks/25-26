{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fc33475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import exp, log\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb777ef",
   "metadata": {},
   "source": [
    "Dense Layer Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e8587f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_Layer:\n",
    "    def __init__(self, inputs, weights, bias, activation):\n",
    "        self.inputs = np.array(inputs)\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "        self.activation = activation\n",
    "\n",
    "    def weighted_sum(self):\n",
    "        return np.dot(self.inputs, self.weights) + self.bias\n",
    "\n",
    "    def activate(self, z):\n",
    "        if self.activation == 'relu':\n",
    "            return np.maximum(0, z)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "        elif self.activation == 'softmax':\n",
    "            exp_vals = np.exp(z - np.max(z))\n",
    "            return exp_vals / np.sum(exp_vals)\n",
    "        else:\n",
    "            return z\n",
    "\n",
    "    def forward(self):\n",
    "        z = self.weighted_sum()\n",
    "        return self.activate(z)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(predicted, target):\n",
    "        predicted = np.clip(predicted, 1e-9, 1-1e-9)\n",
    "        return -np.sum(target * np.log(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58b1c3",
   "metadata": {},
   "source": [
    "Breast Cancer Dataset\n",
    "Using Mean Radius, Mean Texture, Mean Smoothness to classify as Benign (0) or Malignant (1).\n",
    "Network: ReLU → Sigmoid → Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f94665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer 1 Output: [18.58507687  4.81119937 18.02659889  0.        ]\n",
      "Hidden Layer 2 Output: [0.         0.99847681 1.        ]\n",
      "Final Output (Prediction): [0.50048064]\n",
      "Loss: 0.6921863567878115\n"
     ]
    }
   ],
   "source": [
    "# Example inputs (dummy example)\n",
    "X = [17.99, 10.38, 0.118]  # Example malignant tumor features\n",
    "target_output = [1]  # malignant\n",
    "\n",
    "# First hidden layer\n",
    "W1 = np.random.randn(3, 4)\n",
    "B1 = np.random.randn(4)\n",
    "layer1 = Dense_Layer(X, W1, B1, 'relu')\n",
    "out1 = layer1.forward()\n",
    "print('Hidden Layer 1 Output:', out1)\n",
    "\n",
    "# Second hidden layer\n",
    "W2 = np.random.randn(4, 3)\n",
    "B2 = np.random.randn(3)\n",
    "layer2 = Dense_Layer(out1, W2, B2, 'sigmoid')\n",
    "out2 = layer2.forward()\n",
    "print('Hidden Layer 2 Output:', out2)\n",
    "\n",
    "# Output layer\n",
    "W3 = np.random.randn(3, 1)\n",
    "B3 = np.random.randn(1)\n",
    "layer3 = Dense_Layer(out2, W3, B3, 'sigmoid')\n",
    "out3 = layer3.forward()\n",
    "print('Final Output (Prediction):', out3)\n",
    "\n",
    "# Loss\n",
    "loss_val = Dense_Layer.loss(out3, target_output)\n",
    "print('Loss:', loss_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
